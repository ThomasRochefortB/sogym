common:
  tb_log: &tb_log "./tb_logs"
  net_arch: &net_arch     # Same 2 layers of 256 for critic and actor indepent of off-policy or on-policy
    - 2048
    - 2048
    - 1024
    - 1024
    - 512
    - 512

PPO:
  learning_rate: 0.0003
  n_steps: 64
  batch_size: 1024
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: null
  tensorboard_log: *tb_log

SAC:
  verbose: 0
  learning_starts: 4096
  batch_size: 10000
  buffer_size : 1000000
  train_freq: 8
  gradient_steps: 1
  tensorboard_log: *tb_log

TD3:
  verbose: 0
  action_noise:
    mean: 0.0
    sigma: 0.5
  learning_starts: 4096
  batch_size: 1024
  train_freq: 8
  gradient_steps: 1
  tensorboard_log: *tb_log
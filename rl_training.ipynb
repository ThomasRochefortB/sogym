{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e6157f-d831-41f7-b27c-f949e2253f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB3 version: 2.2.1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'       #Disactivate multiprocessing for numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize, SubprocVecEnv\n",
    "from stable_baselines3 import PPO, A2C, SAC, TD3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList, CheckpointCallback\n",
    "\n",
    "from sogym.env import sogym\n",
    "from sogym.mmc_optim import run_mmc\n",
    "from sogym.env import sogym\n",
    "from sogym.expert_generation import generate_expert_dataset, generate_mmc_solutions, generate_dataset\n",
    "from sogym.utils import profile_and_analyze,ImageDictExtractor, CustomBoxDense\n",
    "from sogym.callbacks import FigureRecorderCallback, MaxRewardCallback, GradientNormCallback\n",
    "from sogym.pretraining import pretrain_agent, ExpertDataSet\n",
    "\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import random_split, Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print('SB3 version:', stable_baselines3.__version__)\n",
    "# Let's make the code device agnostic:\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b8cad-4629-49cf-a15e-ebb7c9a5b6c1",
   "metadata": {},
   "source": [
    "---\n",
    "### Environment test and visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a4374a-b735-4474-8427-30b1d55dfe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's test the environment using the check_env util from SB3:\n",
    "observation_type = 'image'\n",
    "train_env = sogym(mode='train',observation_type=observation_type,vol_constraint_type='hard',resolution=50,check_connectivity = True)\n",
    "eval_env = sogym(mode='test',observation_type=observation_type,vol_constraint_type='hard',resolution=50,check_connectivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edcde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will check your custom environment and output additional warnings if needed\n",
    "check_env(sogym(mode='train',observation_type='image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de06f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Specify the number of episodes to run\n",
    "num_episodes = 20\n",
    "# Call the profile_and_analyze function\n",
    "result_df = profile_and_analyze(num_episodes, train_env)\n",
    "# Print the resulting DataFrame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f888890",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = train_env.reset()\n",
    "cfg = {\n",
    "            'optimizer':'mma', #optimiser choice\n",
    "            'xInt':0.25, #initial interval of components in x\n",
    "            'yInt':0.25, #initial interval of components in y\n",
    "            'E':1.0, #Young's modulus\n",
    "            'nu':0.3, #Poisson ratio\n",
    "            'h':1, #thickness\n",
    "            'dgt0':5, #significant digit of sens.\n",
    "            'scl':1, #scale factor for obj\n",
    "            'p':6,  #power of super ellipsoid\n",
    "            'lmd':100, #power of KS aggregation   \n",
    "            'maxiter':500, # maximum number of outer iterations\n",
    "            'alpha':1e-9, # This is the threshold level in the Heaviside function\n",
    "            'epsilon':0.2, #This is the regularization term in the Heaviside function\n",
    "            'maxinnerinit':1, # This is the maximum number of inner iterations for GCMMA\n",
    "            'switch':-0.000002, # This is the switch criteria for the hybrid optimizer\n",
    "            'convergence_threshold':2e-4, #This is the threshold for the relative change in the objective function\n",
    "            'xmin':(0.0, 0.0, 0.0, 0.00, 0.00, -np.pi),\n",
    "            'xmax':(train_env.dx, train_env.dy, 0.7*min(train_env.dx,train_env.dy), 0.05*min(train_env.dx,train_env.dy),0.05*min(train_env.dx,train_env.dy), np.pi)\n",
    "        }\n",
    "\n",
    "#run_mmc(train_env.conditions,train_env.nelx,train_env.nely,train_env.dx,train_env.dy,plotting='contour',verbose=0,cfg=cfg)\n",
    "dataset_folder = \"/home/thomas/Documents/scratch_thomas/GitHub/sogym_v2/dataset/topologies/mmc\"\n",
    "#generate_mmc_solutions(key=0,dataset_folder=\"/home/thomas/Documents/scratch_thomas/GitHub/sogym_v2/dataset/topologies/mmc\")\n",
    "generate_dataset(dataset_folder= dataset_folder, num_threads=32, num_samples=3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the training environment on a random problem statement and visualize a 'successful' solution:\n",
    "reward = 0.0\n",
    "while reward==0.0:\n",
    "    obs = train_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = train_env.action_space.sample()\n",
    "        obs, reward, done,truncated, info = train_env.step(action)\n",
    "        \n",
    "# print(\"Volume: \", train_env.volume)\n",
    "print(\"Reward \",reward)\n",
    "\n",
    "train_env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a21145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axes for the subplots\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Initialize the index for the current subplot\n",
    "subplot_index = 0\n",
    "\n",
    "# Let's visualize the training environment on a random problem statement and visualize a 'successful' solution:\n",
    "reward = 0.0\n",
    "while reward == 0.0:\n",
    "    obs = train_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = train_env.action_space.sample()\n",
    "        obs, reward, done, truncated, info = train_env.step(action)\n",
    "        \n",
    "        # Plot the current observation image\n",
    "        axes[subplot_index].imshow(obs['image'].T, cmap='gray')\n",
    "        axes[subplot_index].axis('off')\n",
    "        axes[subplot_index].set_title(f\"Timestep {subplot_index+1}\")\n",
    "        \n",
    "        # Increment the subplot index\n",
    "        subplot_index += 1\n",
    "        \n",
    "        # If all subplots are filled, display the plot and reset the index\n",
    "        if subplot_index == len(axes):\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            subplot_index = 0\n",
    "\n",
    "# Print the reward\n",
    "print(\"Reward:\", reward)\n",
    "\n",
    "# Plot the final state of the training environment\n",
    "train_env.plot()\n",
    "\n",
    "# Display any remaining subplots\n",
    "if subplot_index > 0:\n",
    "    for i in range(subplot_index, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3f4a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  60%|█████▉    | 1038/1736 [00:45<00:22, 30.42file/s]/scratch/thomas/GitHub/sogym_v2/sogym/struct.py:42: RuntimeWarning: divide by zero encountered in divide\n",
      "  temp = ((x1)**p)/((L**p)) + ((y1)**p)/((l**p))\n",
      "Processing files:  60%|██████    | 1050/1736 [00:45<00:26, 25.68file/s]/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/matplotlib/contour.py:1479: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/matplotlib/contour.py:1480: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "Processing files: 100%|██████████| 1736/1736 [01:15<00:00, 23.11file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify the number of permutations to generate\n",
    "num_permutations = 1\n",
    "observation_type = \"image\"\n",
    "\n",
    "# Specify the environment configuration (optional)\n",
    "env_kwargs = {\n",
    "    'mode': 'train',\n",
    "    'observation_type': 'image',\n",
    "    'vol_constraint_type': 'hard',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "directory_path = \"/home/thomas/Documents/scratch_thomas/GitHub/sogym_v2/dataset/topologies/mmc\"\n",
    "expert_observations, expert_actions = generate_expert_dataset(directory_path,env_kwargs, plot_terminated=False,num_permutations = None)\n",
    "print(len(expert_observations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the expert_dataset defined\n",
    "expert_dataset = ExpertDataSet(expert_observations, expert_actions, train_env)\n",
    "# Get a random sample from the dataset\n",
    "sample_idx = np.random.randint(len(expert_dataset))\n",
    "sample = expert_dataset[sample_idx]\n",
    "\n",
    "# Extract the observation and reward from the sample\n",
    "observation, reward = sample\n",
    "plt.imshow(observation['image'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bfc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Clear the GPU memory\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ad778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_policy = \"MlpPolicy\" if observation_type == 'box_dense' else \"MultiInputPolicy\"\n",
    "\n",
    "feature_extractor = ImageDictExtractor if observation_type == 'image' else CustomBoxDense\n",
    "\n",
    "# Load the YAML file\n",
    "env=train_env\n",
    "\n",
    "with open(\"algorithms.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Extract the parameters for the desired algorithm\n",
    "algorithm_name = \"SAC\"  # or \"TD3\"\n",
    "algorithm_params = config[algorithm_name]\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=feature_extractor,\n",
    "    net_arch = config['common']['net_arch'],\n",
    "    share_features_extractor = True\n",
    ")\n",
    "\n",
    "# Create the model based on the algorithm name and parameters\n",
    "if algorithm_name == \"SAC\":\n",
    "    model = SAC(env=env,\n",
    "                policy = chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                device=device, \n",
    "                **algorithm_params)\n",
    "\n",
    "elif algorithm_name == \"PPO\":\n",
    "    model = PPO(env=env, \n",
    "                policy = chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                device = device, \n",
    "                **algorithm_params)\n",
    "\n",
    "elif algorithm_name == \"TD3\":\n",
    "    # Create the action noise object\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "    action_noise_params = algorithm_params.pop(\"action_noise\")\n",
    "    action_noise = NormalActionNoise(mean=action_noise_params[\"mean\"] * np.ones(n_actions),\n",
    "                                     sigma=action_noise_params[\"sigma\"] * np.ones(n_actions))\n",
    "    model = TD3(env=env,\n",
    "                policy =chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                action_noise=action_noise,\n",
    "                device=device, \n",
    "                **algorithm_params)\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create the tb_log_name string\n",
    "tb_log_name = f\"{algorithm_name}_{current_datetime}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0166b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 20:17:11.719905: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-01 20:17:12.237588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/cv2/../../lib64:/local/cuda-11.3/lib64:/local/TensorRT-7.2.2.3/lib\n",
      "2024-04-01 20:17:12.237738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/cv2/../../lib64:/local/cuda-11.3/lib64:/local/TensorRT-7.2.2.3/lib\n",
      "2024-04-01 20:17:12.237744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: tensorboard, torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/thomasrb/pretraining-rl/a0942c9f8c474739b2fb2502c1c50e5d\n",
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.02 GiB (GPU 0; 23.69 GiB total capacity; 21.27 GiB already allocated; 208.31 MiB free; 21.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpretrain_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpert_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpert_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_env\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_gamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.98\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_curves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensorboard_log_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtb_logs/imitation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoints/imitation_SAC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomet_ml_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNo20MKxPKu7vWLOUQCFBRO8mo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomet_ml_project_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpretraining_rl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomet_ml_experiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPPO_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/thomas/GitHub/sogym_v2/sogym/pretraining.py:254\u001b[0m, in \u001b[0;36mpretrain_agent\u001b[0;34m(student, expert_observations, expert_actions, env, test_env, batch_size, epochs, scheduler_gamma, learning_rate, log_interval, no_cuda, seed, test_batch_size, early_stopping_patience, plot_curves, tensorboard_log_dir, verbose, save_path, comet_ml_api_key, comet_ml_project_name, comet_ml_experiment_name, n_eval_episodes, eval_freq, l2_reg_strength)\u001b[0m\n\u001b[1;32m    251\u001b[0m     experiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 254\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m test(model, device, test_loader)\n\u001b[1;32m    257\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m/scratch/thomas/GitHub/sogym_v2/sogym/pretraining.py:140\u001b[0m, in \u001b[0;36mpretrain_agent.<locals>.train\u001b[0;34m(model, device, train_loader, optimizer, epoch, max_grad_norm)\u001b[0m\n\u001b[1;32m    137\u001b[0m         grad_norm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m param_norm\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    138\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m grad_norm \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m--> 140\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mand\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m log_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    142\u001b[0m     current_lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/torch/optim/adadelta.py:115\u001b[0m, in \u001b[0;36mAdadelta.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(state) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    114\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 115\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquare_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc_delta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n\u001b[1;32m    118\u001b[0m square_avgs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquare_avg\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.02 GiB (GPU 0; 23.69 GiB total capacity; 21.27 GiB already allocated; 208.31 MiB free; 21.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHHCAYAAACvJxw8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAoUlEQVR4nO3deVxV1f7/8fcBmREQlUkBh1DMSAuD0MpuUqhdC4c0vqZglplTpfZVb05ZZmWWpakNt8wmTUuzrmWKDabkrDlfK6c0IDXAERDW7w9/nG8nYIsIIvZ6Ph77kWedtff+rA123u699j42Y4wRAAAASuRU1QUAAABczghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLwGUuJSVFDRo0KNe648ePl81mq9iCLjP79u2TzWbT7Nmzq7oUAFcowhJQTjabrUzLN998U9Wl/u01aNCgTD+rigpczzzzjBYtWlSmvkVh74UXXqiQfVe2jIwMDR8+XJGRkfL09JSXl5eio6P19NNPKysrq6rLAypFjaouAKiu3n33XYfXc+bM0bJly4q1N2vW7KL288Ybb6iwsLBc644ePVojR468qP1fCaZOnaoTJ07YXy9ZskQffvihXnrpJdWpU8fe3rp16wrZ3zPPPKNu3bopMTGxQrZ3uVi3bp06duyoEydO6L777lN0dLQkaf369Xr22Wf13Xff6auvvqriKoGKR1gCyum+++5zeP3DDz9o2bJlxdr/6tSpU/L09CzzflxcXMpVnyTVqFFDNWrw1/yvoSU9PV0ffvihEhMTy32J8+8mKytLnTt3lrOzszZt2qTIyEiH9ydOnKg33nijQvZ18uRJeXl5Vci2gIrAZTigEt1666265pprtGHDBt1yyy3y9PTUv/71L0nSp59+qjvvvFMhISFyc3NT48aN9dRTT6mgoMBhG3+ds/Tnyzavv/66GjduLDc3N91www1at26dw7olzVmy2WwaNGiQFi1apGuuuUZubm5q3ry5vvzyy2L1f/PNN2rVqpXc3d3VuHFjvfbaa2WeB7Vy5Urdc889CgsLk5ubm0JDQ/XYY4/p9OnTxcbn7e2tQ4cOKTExUd7e3qpbt66GDx9e7FhkZWUpJSVFvr6+8vPzU3JycoVe+nnvvfcUHR0tDw8P+fv7695779XBgwcd+uzZs0ddu3ZVUFCQ3N3dVb9+fd17773Kzs6WdO74njx5Uu+884798l5KSspF15aZmam+ffsqMDBQ7u7uatGihd55551i/ebOnavo6GjVrFlTPj4+ioqK0ssvv2x/Pz8/X08++aQiIiLk7u6u2rVr66abbtKyZcss9//aa6/p0KFDevHFF4sFJUkKDAzU6NGj7a9tNpvGjx9frF+DBg0cjsfs2bNls9n07bffasCAAQoICFD9+vW1YMECe3tJtdhsNm3bts3etmvXLnXr1k3+/v5yd3dXq1attHjxYof1yjt2gH9yApXs6NGj6tChg+69917dd999CgwMlHTuQ8Lb21tDhw6Vt7e3VqxYobFjxyonJ0eTJ08+73Y/+OADHT9+XA899JBsNpuef/55denSRb/88st5z0Z9//33+uSTTzRgwADVrFlTr7zyirp27aoDBw6odu3akqRNmzapffv2Cg4O1pNPPqmCggJNmDBBdevWLdO458+fr1OnTunhhx9W7dq1tXbtWk2bNk2//vqr5s+f79C3oKBACQkJio2N1QsvvKDly5drypQpaty4sR5++GFJkjFGd999t77//nv1799fzZo108KFC5WcnFymes5n4sSJGjNmjLp3764HHnhAv//+u6ZNm6ZbbrlFmzZtkp+fn/Ly8pSQkKDc3FwNHjxYQUFBOnTokD7//HNlZWXJ19dX7777rh544AHFxMSoX79+kqTGjRtfVG2nT5/Wrbfeqp9++kmDBg1Sw4YNNX/+fKWkpCgrK0uPPPKIJGnZsmVKSkpSu3bt9Nxzz0mSdu7cqVWrVtn7jB8/XpMmTbLXmJOTo/Xr12vjxo26/fbbS61h8eLF8vDwULdu3S5qLKUZMGCA6tatq7Fjx+rkyZO688475e3trY8++kht27Z16Dtv3jw1b95c11xzjSRp+/btatOmjerVq6eRI0fKy8tLH330kRITE/Xxxx+rc+fOFzV2QAZAhRg4cKD561+ptm3bGklm1qxZxfqfOnWqWNtDDz1kPD09zZkzZ+xtycnJJjw83P567969RpKpXbu2OXbsmL39008/NZLMZ599Zm8bN25csZokGVdXV/PTTz/Z27Zs2WIkmWnTptnbOnXqZDw9Pc2hQ4fsbXv27DE1atQots2SlDS+SZMmGZvNZvbv3+8wPklmwoQJDn2vu+46Ex0dbX+9aNEiI8k8//zz9razZ8+am2++2Ugyb7/99nlrKjJ58mQjyezdu9cYY8y+ffuMs7OzmThxokO/rVu3mho1atjbN23aZCSZ+fPnW27fy8vLJCcnl6mWop/n5MmTS+0zdepUI8m899579ra8vDwTFxdnvL29TU5OjjHGmEceecT4+PiYs2fPlrqtFi1amDvvvLNMtf1ZrVq1TIsWLcrcX5IZN25csfbw8HCHY/P2228bSeamm24qVndSUpIJCAhwaP/tt9+Mk5OTw+9Lu3btTFRUlMPfm8LCQtO6dWsTERFhbyvv2AEuwwGVzM3NTX369CnW7uHhYf/z8ePHdeTIEd188806deqUdu3add7t9ujRQ7Vq1bK/vvnmmyVJv/zyy3nXjY+Pdzjbce2118rHx8e+bkFBgZYvX67ExESFhITY+1111VXq0KHDebcvOY7v5MmTOnLkiFq3bi1jjDZt2lSsf//+/R1e33zzzQ5jWbJkiWrUqGE/0yRJzs7OGjx4cJnqsfLJJ5+osLBQ3bt315EjR+xLUFCQIiIi9PXXX0uSfH19JUlLly7VqVOnLnq/ZbVkyRIFBQUpKSnJ3ubi4qIhQ4boxIkT9ktVfn5+OnnypOVlJT8/P23fvl179uy5oBpycnJUs2bN8g2gDB588EE5Ozs7tPXo0UOZmZkOd5QuWLBAhYWF6tGjhyTp2LFjWrFihbp3727/e3TkyBEdPXpUCQkJ2rNnjw4dOiSp/GMHCEtAJatXr55cXV2LtW/fvl2dO3eWr6+vfHx8VLduXfvk8KL5L1bCwsIcXhcFpz/++OOC1y1av2jdzMxMnT59WldddVWxfiW1leTAgQNKSUmRv7+/fR5S0eWUv47P3d292OW9P9cjSfv371dwcLC8vb0d+jVt2rRM9VjZs2ePjDGKiIhQ3bp1HZadO3cqMzNTktSwYUMNHTpUb775purUqaOEhAS9+uqrZfp5XYz9+/crIiJCTk6O/8suutNy//79ks5dymrSpIk6dOig+vXr6/777y82F23ChAnKyspSkyZNFBUVpccff1w//vjjeWvw8fHR8ePHK2hExTVs2LBYW/v27eXr66t58+bZ2+bNm6eWLVuqSZMmkqSffvpJxhiNGTOm2M9u3LhxkmT/+ZV37ABzloBK9uczLEWysrLUtm1b+fj4aMKECWrcuLHc3d21ceNGjRgxokyPCvjrv8KLGGMqdd2yKCgo0O23365jx45pxIgRioyMlJeXlw4dOqSUlJRi4yutnkulsLBQNptNX3zxRYm1/DmgTZkyRSkpKfr000/11VdfaciQIZo0aZJ++OEH1a9f/1KWXUxAQIA2b96spUuX6osvvtAXX3yht99+W71797ZPBr/lllv0888/2+t/88039dJLL2nWrFl64IEHSt12ZGSkNm/erLy8vBLDf1n9ddJ+kZL+nri5uSkxMVELFy7UjBkzlJGRoVWrVumZZ56x9yn6XRo+fLgSEhJK3HZRwC/v2AHCElAFvvnmGx09elSffPKJbrnlFnv73r17q7Cq/xMQECB3d3f99NNPxd4rqe2vtm7dqv/+979655131Lt3b3v7xdx1FB4ertTUVJ04ccIhvOzevbvc2yzSuHFjGWPUsGFD+xkLK1FRUYqKitLo0aO1evVqtWnTRrNmzdLTTz8tSRX+1PTw8HD9+OOPKiwsdDi7VHS5Njw83N7m6uqqTp06qVOnTiosLNSAAQP02muvacyYMfbQ4O/vrz59+qhPnz46ceKEbrnlFo0fP94yMHTq1ElpaWn6+OOPHS4HlqZWrVrF7lTMy8vTb7/9diFDV48ePfTOO+8oNTVVO3fulDHGfglOkho1aiTp3GXJ+Pj4826vPGMHuAwHVIGisxd/PpOTl5enGTNmVFVJDpydnRUfH69Fixbp8OHD9vaffvpJX3zxRZnWlxzHZ4xxuIX9QnXs2FFnz57VzJkz7W0FBQWaNm1aubdZpEuXLnJ2dtaTTz5Z7OyaMUZHjx6VdG7eztmzZx3ej4qKkpOTk3Jzc+1tXl5eFfpIg44dOyo9Pd3hctTZs2c1bdo0eXt72y9vFtVZxMnJSddee60k2ev7ax9vb29dddVVDvWXpH///goODtawYcP03//+t9j7mZmZ9rAonQug3333nUOf119/vdQzS6WJj4+Xv7+/5s2bp3nz5ikmJsbhkl1AQIBuvfVWvfbaayUGsd9//93+5/KOHeDMElAFWrdurVq1aik5OVlDhgyRzWbTu+++W2GXwSrC+PHj9dVXX6lNmzZ6+OGHVVBQoOnTp+uaa67R5s2bLdeNjIxU48aNNXz4cB06dEg+Pj76+OOPyzSfqjSdOnVSmzZtNHLkSO3bt09XX321PvnkkwqZL9S4cWM9/fTTGjVqlPbt26fExETVrFlTe/fu1cKFC9WvXz8NHz5cK1as0KBBg3TPPfeoSZMmOnv2rN599105Ozura9eu9u1FR0dr+fLlevHFFxUSEqKGDRsqNjbWsobU1FSdOXOmWHtiYqL69eun1157TSkpKdqwYYMaNGigBQsWaNWqVZo6dap94vUDDzygY8eO6bbbblP9+vW1f/9+TZs2TS1btrTPb7r66qt16623Kjo6Wv7+/lq/fr0WLFigQYMGWdZXq1YtLVy4UB07dlTLli0dnuC9ceNGffjhh4qLi7P3f+CBB9S/f3917dpVt99+u7Zs2aKlS5c6PDG9LFxcXNSlSxfNnTtXJ0+eLPFrYV599VXddNNNioqK0oMPPqhGjRopIyNDaWlp+vXXX7Vly5aLGjvAowOAClLaowOaN29eYv9Vq1aZG2+80Xh4eJiQkBDzv//7v2bp0qVGkvn666/t/Up7dEBJt5rrL7drl/bogIEDBxZb96+3dBtjTGpqqrnuuuuMq6urady4sXnzzTfNsGHDjLu7eylH4f/s2LHDxMfHG29vb1OnTh3z4IMP2h9R8Ofb/JOTk42Xl1ex9Uuq/ejRo6ZXr17Gx8fH+Pr6ml69etlv57+YRwcU+fjjj81NN91kvLy8jJeXl4mMjDQDBw40u3fvNsYY88svv5j777/fNG7c2Li7uxt/f3/zj3/8wyxfvtxhO7t27TK33HKL8fDwMJIsHyNQ9PMsbXn33XeNMcZkZGSYPn36mDp16hhXV1cTFRVVbMwLFiwwd9xxhwkICDCurq4mLCzMPPTQQ+a3336z93n66adNTEyM8fPzMx4eHiYyMtJMnDjR5OXllenYHT582Dz22GOmSZMmxt3d3Xh6epro6GgzceJEk52dbe9XUFBgRowYYerUqWM8PT1NQkKC+emnn0p9dMC6detK3eeyZcuMJGOz2czBgwdL7PPzzz+b3r17m6CgIOPi4mLq1atn/vnPf5oFCxZU2Njx92Uz5jL6pyyAy15iYiK3XwP4W2HOEoBS/fWrSfbs2aMlS5bo1ltvrZqCAKAKcGYJQKmCg4OVkpKiRo0aaf/+/Zo5c6Zyc3O1adMmRUREVHV5AHBJMMEbQKnat2+vDz/8UOnp6XJzc1NcXJyeeeYZghKAvxXOLAEAAFhgzhIAAIAFwhIAAIAF5ixVgMLCQh0+fFg1a9as8K85AAAAlcMYo+PHjyskJKTYF1X/GWGpAhw+fFihoaFVXQYAACiHgwcPWn4RNmGpAhR91cDBgwfl4+NTxdUAAICyyMnJUWhoqP1zvDSEpQpQdOnNx8eHsAQAQDVzvik0TPAGAACwQFgCAACwQFgCAACwwJwlAAD+pKCgQPn5+VVdBiqAi4uLnJ2dL3o7hCUAAHTumTvp6enKysqq6lJQgfz8/BQUFHRRz0EkLAEAINmDUkBAgDw9PXnIcDVnjNGpU6eUmZkpSQoODi73tghLAIC/vYKCAntQql27dlWXgwri4eEhScrMzFRAQEC5L8kxwRsA8LdXNEfJ09OziitBRSv6mV7MPDTCEgAA/x+X3q48FfEzJSwBAABYICwBAAAHDRo00NSpU6u6jMsGYQkAgGrKZrNZLuPHjy/XdtetW6d+/fpdVG233nqrHn300YvaxuWCu+EAAKimfvvtN/uf582bp7Fjx2r37t32Nm9vb/ufjTEqKChQjRrn/+ivW7duxRZazXFmCQCAaiooKMi++Pr6ymaz2V/v2rVLNWvW1BdffKHo6Gi5ubnp+++/188//6y7775bgYGB8vb21g033KDly5c7bPevl+FsNpvefPNNde7cWZ6enoqIiNDixYsvqvaPP/5YzZs3l5ubmxo0aKApU6Y4vD9jxgxFRETI3d1dgYGB6tatm/29BQsWKCoqSh4eHqpdu7bi4+N18uTJi6rHCmeWAAAogTFGp/MLqmTfHi7OFXZn3siRI/XCCy+oUaNGqlWrlg4ePKiOHTtq4sSJcnNz05w5c9SpUyft3r1bYWFhpW7nySef1PPPP6/Jkydr2rRp6tmzp/bv3y9/f/8LrmnDhg3q3r27xo8frx49emj16tUaMGCAateurZSUFK1fv15DhgzRu+++q9atW+vYsWNauXKlpHNn05KSkvT888+rc+fOOn78uFauXCljTLmP0fkQlgAAKMHp/AJdPXZplex7x4QEebpWzEf0hAkTdPvtt9tf+/v7q0WLFvbXTz31lBYuXKjFixdr0KBBpW4nJSVFSUlJkqRnnnlGr7zyitauXav27dtfcE0vvvii2rVrpzFjxkiSmjRpoh07dmjy5MlKSUnRgQMH5OXlpX/+85+qWbOmwsPDdd1110k6F5bOnj2rLl26KDw8XJIUFRV1wTVcCC7DAQBwBWvVqpXD6xMnTmj48OFq1qyZ/Pz85O3trZ07d+rAgQOW27n22mvtf/by8pKPj4/9q0Qu1M6dO9WmTRuHtjZt2mjPnj0qKCjQ7bffrvDwcDVq1Ei9evXS+++/r1OnTkmSWrRooXbt2ikqKkr33HOP3njjDf3xxx/lqqOsOLMEAEAJPFyctWNCQpXtu6J4eXk5vB4+fLiWLVumF154QVdddZU8PDzUrVs35eXlWW7HxcXF4bXNZlNhYWGF1flnNWvW1MaNG/XNN9/oq6++0tixYzV+/HitW7dOfn5+WrZsmVavXq2vvvpK06ZN0xNPPKE1a9aoYcOGlVIPYQkAgBLYbLYKuxR2OVm1apVSUlLUuXNnSefONO3bt++S1tCsWTOtWrWqWF1NmjSxf39bjRo1FB8fr/j4eI0bN05+fn5asWKFunTpIpvNpjZt2qhNmzYaO3aswsPDtXDhQg0dOrRS6r3yfgsAAECpIiIi9Mknn6hTp06y2WwaM2ZMpZ0h+v3337V582aHtuDgYA0bNkw33HCDnnrqKfXo0UNpaWmaPn26ZsyYIUn6/PPP9csvv+iWW25RrVq1tGTJEhUWFqpp06Zas2aNUlNTdccddyggIEBr1qzR77//rmbNmlXKGCTCEgAAfysvvvii7r//frVu3Vp16tTRiBEjlJOTUyn7+uCDD/TBBx84tD311FMaPXq0PvroI40dO1ZPPfWUgoODNWHCBKWkpEiS/Pz89Mknn2j8+PE6c+aMIiIi9OGHH6p58+bauXOnvvvuO02dOlU5OTkKDw/XlClT1KFDh0oZgyTZTGXea/c3kZOTI19fX2VnZ8vHx6eqywEAXKAzZ85o7969atiwodzd3au6HFQgq59tWT+/uRsOAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAIBqymazWS7jx4+/qG0vWrSowvpVZ3yRLgAA1dRvv/1m//O8efM0duxY7d69297m7e1dFWVdcTizBABANRUUFGRffH19ZbPZHNrmzp2rZs2ayd3dXZGRkZoxY4Z93by8PA0aNEjBwcFyd3dXeHi4Jk2aJElq0KCBJKlz586y2Wz21xeqsLBQEyZMUP369eXm5qaWLVvqyy+/LFMNxhiNHz9eYWFhcnNzU0hIiIYMGVK+A3WROLMEAEBJjJHyT1XNvl08JZvtojbx/vvva+zYsZo+fbquu+46bdq0SQ8++KC8vLyUnJysV155RYsXL9ZHH32ksLAwHTx4UAcPHpQkrVu3TgEBAXr77bfVvn17OTs7l6uGl19+WVOmTNFrr72m6667Tm+99Zbuuusubd++XREREZY1fPzxx3rppZc0d+5cNW/eXOnp6dqyZctFHZPyIiwBAFCS/FPSMyFVs+9/HZZcvS5qE+PGjdOUKVPUpUsXSVLDhg21Y8cOvfbaa0pOTtaBAwcUERGhm266STabTeHh4fZ169atK0ny8/NTUFBQuWt44YUXNGLECN17772SpOeee05ff/21pk6dqldffdWyhgMHDigoKEjx8fFycXFRWFiYYmJiyl3LxeAyHAAAV5iTJ0/q559/Vt++feXt7W1fnn76af3888+SpJSUFG3evFlNmzbVkCFD9NVXX1VoDTk5OTp8+LDatGnj0N6mTRvt3LnzvDXcc889On36tBo1aqQHH3xQCxcu1NmzZyu0xrLizBIAACVx8Tx3hqeq9n0RTpw4IUl64403FBsb6/Be0SW166+/Xnv37tUXX3yh5cuXq3v37oqPj9eCBQsuat8XwqqG0NBQ7d69W8uXL9eyZcs0YMAATZ48Wd9++61cXFwuWY0SYQkAgJLZbBd9KayqBAYGKiQkRL/88ot69uxZaj8fHx/16NFDPXr0ULdu3dS+fXsdO3ZM/v7+cnFxUUFBQblr8PHxUUhIiFatWqW2bdva21etWuVwOc2qBg8PD3Xq1EmdOnXSwIEDFRkZqa1bt+r6668vd13lQVgCAOAK9OSTT2rIkCHy9fVV+/btlZubq/Xr1+uPP/7Q0KFD9eKLLyo4OFjXXXednJycNH/+fAUFBcnPz0/SuTviUlNT1aZNG7m5ualWrVql7mvv3r3avHmzQ1tERIQef/xxjRs3To0bN1bLli319ttva/PmzXr//fclybKG2bNnq6CgQLGxsfL09NR7770nDw8Ph3lNlwphCQCAK9ADDzwgT09PTZ48WY8//ri8vLwUFRWlRx99VJJUs2ZNPf/889qzZ4+cnZ11ww03aMmSJXJyOjedecqUKRo6dKjeeOMN1atXT/v27St1X0OHDi3WtnLlSg0ZMkTZ2dkaNmyYMjMzdfXVV2vx4sWKiIg4bw1+fn569tlnNXToUBUUFCgqKkqfffaZateuXeHH6nxsxhhzyfd6hcnJyZGvr6+ys7Pl4+NT1eUAAC7QmTNntHfvXjVs2FDu7u5VXQ4qkNXPtqyf39XubrhXX31VDRo0kLu7u2JjY7V27VrL/vPnz1dkZKTc3d0VFRWlJUuWlNq3f//+stlsmjp1agVXDQAAqqtqFZbmzZunoUOHaty4cdq4caNatGihhIQEZWZmlth/9erVSkpKUt++fbVp0yYlJiYqMTFR27ZtK9Z34cKF+uGHHxQSUkXP1AAAAJelahWWXnzxRT344IPq06ePrr76as2aNUuenp566623Suz/8ssvq3379nr88cfVrFkzPfXUU7r++us1ffp0h36HDh3S4MGD9f7771/y2xEBAMDlrdqEpby8PG3YsEHx8fH2NicnJ8XHxystLa3EddLS0hz6S1JCQoJD/8LCQvXq1UuPP/64mjdvXjnFAwCAaqva3A135MgRFRQUKDAw0KE9MDBQu3btKnGd9PT0Evunp6fbXz/33HOqUaPGBX05X25urnJzc+2vc3JyyrwuAODyxT1PV56K+JlWmzNLlWHDhg16+eWXNXv2bNku4AsLJ02aJF9fX/sSGhpaiVUCACpb0RSMU6eq6ItzUWmKfqYXM82m2pxZqlOnjpydnZWRkeHQnpGRUeqX/AUFBVn2X7lypTIzMxUWFmZ/v6CgQMOGDdPUqVNLfabEqFGjHJ4pkZOTQ2ACgGrM2dlZfn5+9huGPD09L+gf0bj8GGN06tQpZWZmys/Pz/41L+VRbcKSq6uroqOjlZqaqsTEREnn5hulpqZq0KBBJa4TFxen1NRU+wO4JGnZsmWKi4uTJPXq1avEOU29evVSnz59Sq3Fzc1Nbm5uFzcgAMBlpegf0qXdYY3qyc/Pr9STKmVVbcKSdO4JocnJyWrVqpViYmI0depUnTx50h5sevfurXr16mnSpEmSpEceeURt27bVlClTdOedd2ru3Llav369Xn/9dUlS7dq1iz0J1MXFRUFBQWratOmlHRwAoErZbDYFBwcrICBA+fn5VV0OKoCLi8tFnVEqUq3CUo8ePfT7779r7NixSk9PV8uWLfXll1/aJ3EfOHDA/ph2SWrdurU++OADjR49Wv/6178UERGhRYsW6ZprrqmqIQAALnPOzs4V8gGLKwdfd1IB+LoTAACqnyv2604AAAAuJcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACAhWoXll599VU1aNBA7u7uio2N1dq1ay37z58/X5GRkXJ3d1dUVJSWLFlify8/P18jRoxQVFSUvLy8FBISot69e+vw4cOVPQwAAFBNVKuwNG/ePA0dOlTjxo3Txo0b1aJFCyUkJCgzM7PE/qtXr1ZSUpL69u2rTZs2KTExUYmJidq2bZsk6dSpU9q4caPGjBmjjRs36pNPPtHu3bt11113XcphAQCAy5jNGGOquoiyio2N1Q033KDp06dLkgoLCxUaGqrBgwdr5MiRxfr36NFDJ0+e1Oeff25vu/HGG9WyZUvNmjWrxH2sW7dOMTEx2r9/v8LCwspUV05Ojnx9fZWdnS0fH59yjAwAAFxqZf38rjZnlvLy8rRhwwbFx8fb25ycnBQfH6+0tLQS10lLS3PoL0kJCQml9pek7Oxs2Ww2+fn5VUjdAACgeqtR1QWU1ZEjR1RQUKDAwECH9sDAQO3atavEddLT00vsn56eXmL/M2fOaMSIEUpKSrJMmLm5ucrNzbW/zsnJKeswAABANVNtzixVtvz8fHXv3l3GGM2cOdOy76RJk+Tr62tfQkNDL1GVAADgUqs2YalOnTpydnZWRkaGQ3tGRoaCgoJKXCcoKKhM/YuC0v79+7Vs2bLzzjsaNWqUsrOz7cvBgwfLMSIAAFAdVJuw5OrqqujoaKWmptrbCgsLlZqaqri4uBLXiYuLc+gvScuWLXPoXxSU9uzZo+XLl6t27drnrcXNzU0+Pj4OCwAAuDJVmzlLkjR06FAlJyerVatWiomJ0dSpU3Xy5En16dNHktS7d2/Vq1dPkyZNkiQ98sgjatu2raZMmaI777xTc+fO1fr16/X6669LOheUunXrpo0bN+rzzz9XQUGBfT6Tv7+/XF1dq2agAADgslGtwlKPHj30+++/a+zYsUpPT1fLli315Zdf2idxHzhwQE5O/3eyrHXr1vrggw80evRo/etf/1JERIQWLVqka665RpJ06NAhLV68WJLUsmVLh319/fXXuvXWWy/JuAAAwOWrWj1n6XLFc5YAAKh+rrjnLAEAAFQFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAICFcoWlgwcP6tdff7W/Xrt2rR599FG9/vrrFVYYAADA5aBcYel//ud/9PXXX0uS0tPTdfvtt2vt2rV64oknNGHChAotEAAAoCqVKyxt27ZNMTExkqSPPvpI11xzjVavXq33339fs2fPrsj6AAAAqlS5wlJ+fr7c3NwkScuXL9ddd90lSYqMjNRvv/1WcdUBAABUsXKFpebNm2vWrFlauXKlli1bpvbt20uSDh8+rNq1a1dogQAAAFWpXGHpueee02uvvaZbb71VSUlJatGihSRp8eLF9stzAAAAVwKbMcaUZ8WCggLl5OSoVq1a9rZ9+/bJ09NTAQEBFVZgdZCTkyNfX19lZ2fLx8enqssBAABlUNbP73KdWTp9+rRyc3PtQWn//v2aOnWqdu/e/bcLSgAA4MpWrrB09913a86cOZKkrKwsxcbGasqUKUpMTNTMmTMrtMC/evXVV9WgQQO5u7srNjZWa9eutew/f/58RUZGyt3dXVFRUVqyZInD+8YYjR07VsHBwfLw8FB8fLz27NlTmUMAAADVSLnC0saNG3XzzTdLkhYsWKDAwEDt379fc+bM0SuvvFKhBf7ZvHnzNHToUI0bN04bN25UixYtlJCQoMzMzBL7r169WklJSerbt682bdqkxMREJSYmatu2bfY+zz//vF555RXNmjVLa9askZeXlxISEnTmzJlKGwcAAKg+yjVnydPTU7t27VJYWJi6d++u5s2ba9y4cTp48KCaNm2qU6dOVUatio2N1Q033KDp06dLkgoLCxUaGqrBgwdr5MiRxfr36NFDJ0+e1Oeff25vu/HGG9WyZUvNmjVLxhiFhIRo2LBhGj58uCQpOztbgYGBmj17tu69994y1cWcJQAAqp9KnbN01VVXadGiRTp48KCWLl2qO+64Q5KUmZlZaWEhLy9PGzZsUHx8vL3NyclJ8fHxSktLK3GdtLQ0h/6SlJCQYO+/d+9epaenO/Tx9fVVbGxsqduUpNzcXOXk5DgsAADgylSusDR27FgNHz5cDRo0UExMjOLi4iRJX331la677roKLbDIkSNHVFBQoMDAQIf2wMBApaenl7hOenq6Zf+i/17INiVp0qRJ8vX1tS+hoaEXPB4AAFA9lCssdevWTQcOHND69eu1dOlSe3u7du300ksvVVhxl6tRo0YpOzvbvhw8eLCqSwIAAJWkRnlXDAoKUlBQkH799VdJUv369Sv1gZR16tSRs7OzMjIyHNozMjIUFBRUao1W/Yv+m5GRoeDgYIc+LVu2LLUWNzc3+9e9AACAK1u5ziwVFhZqwoQJ8vX1VXh4uMLDw+Xn56ennnpKhYWFFV2jJMnV1VXR0dFKTU11qCM1NdV+GfCv4uLiHPpL0rJly+z9GzZsqKCgIIc+OTk5WrNmTanbBAAAfy/lOrP0xBNP6N///reeffZZtWnTRpL0/fffa/z48Tpz5owmTpxYoUUWGTp0qJKTk9WqVSvFxMRo6tSpOnnypPr06SNJ6t27t+rVq6dJkyZJkh555BG1bdtWU6ZM0Z133qm5c+dq/fr1ev311yVJNptNjz76qJ5++mlFRESoYcOGGjNmjEJCQpSYmFgpYwAAANWMKYfg4GDz6aefFmtftGiRCQkJKc8my2zatGkmLCzMuLq6mpiYGPPDDz/Y32vbtq1JTk526P/RRx+ZJk2aGFdXV9O8eXPzn//8x+H9wsJCM2bMGBMYGGjc3NxMu3btzO7duy+opuzsbCPJZGdnl3tcAADg0irr53e5nrPk7u6uH3/8UU2aNHFo3717t1q2bKnTp09XUJSrHnjOEgAA1U+lPmepRYsW9gdD/tn06dN17bXXlmeTAAAAl6VyzVl6/vnndeedd2r58uX2idBpaWk6ePBgse9eAwAAqM7KdWapbdu2+u9//6vOnTsrKytLWVlZ6tKli7Zv36533323omsEAACoMuWas1SaLVu26Prrr1dBQUFFbbJaYM4SAADVT6XOWQIAAPi7ICwBAABYICwBAABYuKC74bp06WL5flZW1sXUAgAAcNm5oLDk6+t73vd79+59UQUBAABcTi4oLL399tuVVQcAAMBliTlLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFqpNWDp27Jh69uwpHx8f+fn5qW/fvjpx4oTlOmfOnNHAgQNVu3ZteXt7q2vXrsrIyLC/v2XLFiUlJSk0NFQeHh5q1qyZXn755coeCgAAqEaqTVjq2bOntm/frmXLlunzzz/Xd999p379+lmu89hjj+mzzz7T/Pnz9e233+rw4cPq0qWL/f0NGzYoICBA7733nrZv364nnnhCo0aN0vTp0yt7OAAAoJqwGWNMVRdxPjt37tTVV1+tdevWqVWrVpKkL7/8Uh07dtSvv/6qkJCQYutkZ2erbt26+uCDD9StWzdJ0q5du9SsWTOlpaXpxhtvLHFfAwcO1M6dO7VixYoy15eTkyNfX19lZ2fLx8enHCMEAACXWlk/v6vFmaW0tDT5+fnZg5IkxcfHy8nJSWvWrClxnQ0bNig/P1/x8fH2tsjISIWFhSktLa3UfWVnZ8vf39+yntzcXOXk5DgsAADgylQtwlJ6eroCAgIc2mrUqCF/f3+lp6eXuo6rq6v8/Pwc2gMDA0tdZ/Xq1Zo3b955L+9NmjRJvr6+9iU0NLTsgwEAANVKlYalkSNHymazWS67du26JLVs27ZNd999t8aNG6c77rjDsu+oUaOUnZ1tXw4ePHhJagQAAJdejarc+bBhw5SSkmLZp1GjRgoKClJmZqZD+9mzZ3Xs2DEFBQWVuF5QUJDy8vKUlZXlcHYpIyOj2Do7duxQu3bt1K9fP40ePfq8dbu5ucnNze28/QAAQPVXpWGpbt26qlu37nn7xcXFKSsrSxs2bFB0dLQkacWKFSosLFRsbGyJ60RHR8vFxUWpqanq2rWrJGn37t06cOCA4uLi7P22b9+u2267TcnJyZo4cWIFjAoAAFxJqsXdcJLUoUMHZWRkaNasWcrPz1efPn3UqlUrffDBB5KkQ4cOqV27dpozZ45iYmIkSQ8//LCWLFmi2bNny8fHR4MHD5Z0bm6SdO7S22233aaEhARNnjzZvi9nZ+cyhbgi3A0HAED1U9bP7yo9s3Qh3n//fQ0aNEjt2rWTk5OTunbtqldeecX+fn5+vnbv3q1Tp07Z21566SV739zcXCUkJGjGjBn29xcsWKDff/9d7733nt577z17e3h4uPbt23dJxgUAAC5v1ebM0uWMM0sAAFQ/V9RzlgAAAKoKYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMBCtQlLx44dU8+ePeXj4yM/Pz/17dtXJ06csFznzJkzGjhwoGrXri1vb2917dpVGRkZJfY9evSo6tevL5vNpqysrEoYAQAAqI6qTVjq2bOntm/frmXLlunzzz/Xd999p379+lmu89hjj+mzzz7T/Pnz9e233+rw4cPq0qVLiX379u2ra6+9tjJKBwAA1ZjNGGOquojz2blzp66++mqtW7dOrVq1kiR9+eWX6tixo3799VeFhIQUWyc7O1t169bVBx98oG7dukmSdu3apWbNmiktLU033nijve/MmTM1b948jR07Vu3atdMff/whPz+/MteXk5MjX19fZWdny8fH5+IGCwAALomyfn5XizNLaWlp8vPzswclSYqPj5eTk5PWrFlT4jobNmxQfn6+4uPj7W2RkZEKCwtTWlqavW3Hjh2aMGGC5syZIyensh2O3Nxc5eTkOCwAAODKVC3CUnp6ugICAhzaatSoIX9/f6Wnp5e6jqura7EzRIGBgfZ1cnNzlZSUpMmTJyssLKzM9UyaNEm+vr72JTQ09MIGBAAAqo0qDUsjR46UzWazXHbt2lVp+x81apSaNWum++6774LXy87Oti8HDx6spAoBAEBVq1GVOx82bJhSUlIs+zRq1EhBQUHKzMx0aD979qyOHTumoKCgEtcLCgpSXl6esrKyHM4uZWRk2NdZsWKFtm7dqgULFkiSiqZv1alTR0888YSefPLJErft5uYmNze3sgwRAABUc1UalurWrau6deuet19cXJyysrK0YcMGRUdHSzoXdAoLCxUbG1viOtHR0XJxcVFqaqq6du0qSdq9e7cOHDiguLg4SdLHH3+s06dP29dZt26d7r//fq1cuVKNGze+2OEBAIArQJWGpbJq1qyZ2rdvrwcffFCzZs1Sfn6+Bg0apHvvvdd+J9yhQ4fUrl07zZkzRzExMfL19VXfvn01dOhQ+fv7y8fHR4MHD1ZcXJz9Tri/BqIjR47Y93chd8MBAIArV7UIS5L0/vvva9CgQWrXrp2cnJzUtWtXvfLKK/b38/PztXv3bp06dcre9tJLL9n75ubmKiEhQTNmzKiK8gEAQDVVLZ6zdLnjOUsAAFQ/V9RzlgAAAKoKYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMACYQkAAMBCjaou4EpgjJEk5eTkVHElAACgrIo+t4s+x0tDWKoAx48flySFhoZWcSUAAOBCHT9+XL6+vqW+bzPni1M4r8LCQh0+fFg1a9aUzWar6nKqVE5OjkJDQ3Xw4EH5+PhUdTlXLI7zpcOxvjQ4zpcGx9mRMUbHjx9XSEiInJxKn5nEmaUK4OTkpPr161d1GZcVHx8f/iJeAhznS4djfWlwnC8NjvP/sTqjVIQJ3gAAABYISwAAABYIS6hQbm5uGjdunNzc3Kq6lCsax/nS4VhfGhznS4PjXD5M8AYAALDAmSUAAAALhCUAAAALhCUAAAALhCUAAAALhCVcsGPHjqlnz57y8fGRn5+f+vbtqxMnTliuc+bMGQ0cOFC1a9eWt7e3unbtqoyMjBL7Hj16VPXr15fNZlNWVlYljKB6qIzjvGXLFiUlJSk0NFQeHh5q1qyZXn755coeymXl1VdfVYMGDeTu7q7Y2FitXbvWsv/8+fMVGRkpd3d3RUVFacmSJQ7vG2M0duxYBQcHy8PDQ/Hx8dqzZ09lDqFaqMjjnJ+frxEjRigqKkpeXl4KCQlR7969dfjw4coexmWvon+f/6x///6y2WyaOnVqBVddDRngArVv3960aNHC/PDDD2blypXmqquuMklJSZbr9O/f34SGhprU1FSzfv16c+ONN5rWrVuX2Pfuu+82HTp0MJLMH3/8UQkjqB4q4zj/+9//NkOGDDHffPON+fnnn827775rPDw8zLRp0yp7OJeFuXPnGldXV/PWW2+Z7du3mwcffND4+fmZjIyMEvuvWrXKODs7m+eff97s2LHDjB492ri4uJitW7fa+zz77LPG19fXLFq0yGzZssXcddddpmHDhub06dOXaliXnYo+zllZWSY+Pt7MmzfP7Nq1y6SlpZmYmBgTHR19KYd12amM3+cin3zyiWnRooUJCQkxL730UiWP5PJHWMIF2bFjh5Fk1q1bZ2/74osvjM1mM4cOHSpxnaysLOPi4mLmz59vb9u5c6eRZNLS0hz6zpgxw7Rt29akpqb+rcNSZR/nPxswYID5xz/+UXHFX8ZiYmLMwIED7a8LCgpMSEiImTRpUon9u3fvbu68806HttjYWPPQQw8ZY4wpLCw0QUFBZvLkyfb3s7KyjJubm/nwww8rYQTVQ0Uf55KsXbvWSDL79++vmKKroco6zr/++qupV6+e2bZtmwkPDycsGWO4DIcLkpaWJj8/P7Vq1creFh8fLycnJ61Zs6bEdTZs2KD8/HzFx8fb2yIjIxUWFqa0tDR7244dOzRhwgTNmTPH8gsN/w4q8zj/VXZ2tvz9/Suu+MtUXl6eNmzY4HB8nJycFB8fX+rxSUtLc+gvSQkJCfb+e/fuVXp6ukMfX19fxcbGWh7zK1llHOeSZGdny2azyc/Pr0Lqrm4q6zgXFhaqV69eevzxx9W8efPKKb4a+nt/IuGCpaenKyAgwKGtRo0a8vf3V3p6eqnruLq6FvufWmBgoH2d3NxcJSUlafLkyQoLC6uU2quTyjrOf7V69WrNmzdP/fr1q5C6L2dHjhxRQUGBAgMDHdqtjk96erpl/6L/Xsg2r3SVcZz/6syZMxoxYoSSkpL+tl8GW1nH+bnnnlONGjU0ZMiQii+6GiMsQZI0cuRI2Ww2y2XXrl2Vtv9Ro0apWbNmuu+++yptH5eDqj7Of7Zt2zbdfffdGjdunO64445Lsk/gYuXn56t79+4yxmjmzJlVXc4VZcOGDXr55Zc1e/Zs2Wy2qi7nslKjqgvA5WHYsGFKSUmx7NOoUSMFBQUpMzPTof3s2bM6duyYgoKCSlwvKChIeXl5ysrKcjjrkZGRYV9nxYoV2rp1qxYsWCDp3B1GklSnTh098cQTevLJJ8s5sstLVR/nIjt27FC7du3Ur18/jR49ulxjqW7q1KkjZ2fnYndhlnR8igQFBVn2L/pvRkaGgoODHfq0bNmyAquvPirjOBcpCkr79+/XihUr/rZnlaTKOc4rV65UZmamw9n9goICDRs2TFOnTtW+ffsqdhDVSVVPmkL1UjTxeP369fa2pUuXlmni8YIFC+xtu3btcph4/NNPP5mtW7fal7feestIMqtXry71zo4rWWUdZ2OM2bZtmwkICDCPP/545Q3gMhUTE2MGDRpkf11QUGDq1atnOSH2n//8p0NbXFxcsQneL7zwgv397OxsJnhX8HE2xpi8vDyTmJhomjdvbjIzMyun8Gqmoo/zkSNHHP4/vHXrVhMSEmJGjBhhdu3aVXkDqQYIS7hg7du3N9ddd51Zs2aN+f77701ERITDLe2//vqradq0qVmzZo29rX///iYsLMysWLHCrF+/3sTFxZm4uLhS9/H111//re+GM6ZyjvPWrVtN3bp1zX333Wd+++03+/J3+fCZO3eucXNzM7NnzzY7duww/fr1M35+fiY9Pd0YY0yvXr3MyJEj7f1XrVplatSoYV544QWzc+dOM27cuBIfHeDn52c+/fRT8+OPP5q7776bRwdU8HHOy8szd911l6lfv77ZvHmzw+9ubm5ulYzxclAZv89/xd1w5xCWcMGOHj1qkpKSjLe3t/Hx8TF9+vQxx48ft7+/d+9eI8l8/fXX9rbTp0+bAQMGmFq1ahlPT0/TuXNn89tvv5W6D8JS5RzncePGGUnFlvDw8Es4sqo1bdo0ExYWZlxdXU1MTIz54Ycf7O+1bdvWJCcnO/T/6KOPTJMmTYyrq6tp3ry5+c9//uPwfmFhoRkzZowJDAw0bm5upl27dmb37t2XYiiXtYo8zkW/6yUtf/79/zuq6N/nvyIsnWMz5v9PDgEAAEAx3A0HAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAJXAZrNp0aJFVV0GgApAWAJwxUlJSZHNZiu2tG/fvqpLA1AN1ajqAgCgMrRv315vv/22Q5ubm1sVVQOgOuPMEoArkpubm4KCghyWWrVqSTp3iWzmzJnq0KGDPDw81KhRIy1YsMBh/a1bt+q2226Th4eHateurX79+unEiRMOfd566y01b95cbm5uCg4O1qBBgxzeP3LkiDp37ixPT09FRERo8eLFlTtoAJWCsATgb2nMmDHq2rWrtmzZop49e+ree+/Vzp07JUknT55UQkKCatWqpXXr1mn+/Plavny5QxiaOXOmBg4cqH79+mnr1q1avHixrrrqKod9PPnkk+revbt+/PFHdezYUT179tSxY8cu6TgBVICq/iZfAKhoycnJxtnZ2Xh5eTksEydONMYYI8n079/fYZ3Y2Fjz8MMPG2OMef31102tWrXMiRMn7O//5z//MU5OTiY9Pd0YY0xISIh54oknSq1Bkhk9erT99YkTJ4wk88UXX1TYOAFcGsxZAnBF+sc//qGZM2c6tPn7+9v/HBcX5/BeXFycNm/eLEnauXOnWrRoIS8vL/v7bdq0UWFhoXbv3i2bzabDhw+rXbt2ljVce+219j97eXnJx8dHmZmZ5R0SgCpCWAJwRfLy8ip2WayieHh4lKmfi4uLw2ubzabCwsLKKAlAJWLOEoC/pR9++KHY62bNmkmSmjVrpi1btujkyZP291etWiUnJyc1bdpUNWvWVIMGDZSamnpJawZQNTizBOCKlJubq/T0dIe2GjVqqE6dOpKk+fPnq1WrVrrpppv0/vvva+3atfr3v/8tSerZs6fGjRun5ORkjR8/Xr///rsGDx6sXr16KTAwUJI0fvx49e/fXwEBAerQoYOOHz+uVatWafDgwZd2oAAqHWEJwBXpyy+/VHBwsENb06ZNtWvXLknn7lSbO3euBgwYoODgYH344Ye6+uqrJUmenp5aunSpHnnkEd1www3y9PRU165d9eKLL9q3lZycrDNnzuill17S8OHDVadOHXXr1u3SDRDAJWMzxpiqLgIALiWbzaaFCxcqMTGxqksBUA0wZwkAAMACYQkAAMACc5YA/O0w+wDAheDMEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgIX/B/fTWJKOsxXMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrain_agent(\n",
    "    model,\n",
    "    expert_observations,\n",
    "    expert_actions,\n",
    "    env,\n",
    "    test_env = eval_env,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    scheduler_gamma=0.98,\n",
    "    learning_rate=3e-4,\n",
    "    log_interval=5,\n",
    "    no_cuda=False,\n",
    "    seed=1,\n",
    "    verbose=True,\n",
    "    test_batch_size=512,\n",
    "    early_stopping_patience=300,\n",
    "    plot_curves=True,\n",
    "    tensorboard_log_dir=\"tb_logs/imitation\",\n",
    "    save_path=\"checkpoints/imitation_SAC\",\n",
    "    comet_ml_api_key=\"No20MKxPKu7vWLOUQCFBRO8mo\",\n",
    "    comet_ml_project_name=\"pretraining_rl\",\n",
    "    comet_ml_experiment_name=\"PPO_1\",\n",
    "    eval_freq = 20,\n",
    "    l2_reg_strength=0.00001,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820005a-be57-4236-b66b-0b34ed558aff",
   "metadata": {},
   "source": [
    "---\n",
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e210c1-817a-42a8-ab28-2ea437ed2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoTokenizer, AutoModel\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecCheckNan\n",
    "import multiprocessing\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\")\n",
    "#model = AutoModel.from_pretrained(\"huggingface/CodeBERTa-small-v1\").to('cuda')\n",
    "\n",
    "# Set number of cpus to use automatically:\n",
    "num_cpu = multiprocessing.cpu_count()\n",
    "num_cpu = 1\n",
    "\n",
    "print(\"Using {} cpus!\".format(num_cpu))\n",
    "observation_type = \"image\"\n",
    "\n",
    "train_env = sogym(mode='train',observation_type=observation_type,vol_constraint_type = 'hard',resolution=50,check_connectivity=True)#,model=model,tokenizer=tokenizer)\n",
    "env= make_vec_env(lambda:train_env, n_envs=num_cpu,vec_env_cls=SubprocVecEnv)\n",
    "env = VecCheckNan(env, raise_exception=True)\n",
    "#env=VecNormalize(env,gamma=1.0)\n",
    "\n",
    "eval_env = sogym(mode='test',observation_type=observation_type,vol_constraint_type='hard',resolution=50,check_connectivity=True)#,model=model,tokenizer=tokenizer)\n",
    "eval_env = make_vec_env(lambda:eval_env, n_envs=1,vec_env_cls=SubprocVecEnv)\n",
    "#eval_env =VecNormalize(eval_env,gamma=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b6f2e-5ceb-447f-ac10-a52f0379cb31",
   "metadata": {},
   "source": [
    "--- \n",
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1132db-34f4-4a72-bb12-1339a9e00a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_policy = \"MlpPolicy\" if observation_type == 'box_dense' else \"MultiInputPolicy\"\n",
    "\n",
    "feature_extractor = ImageDictExtractor if observation_type == 'image' else CustomBoxDense\n",
    "\n",
    "# Load the YAML file\n",
    "with open(\"algorithms.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Extract the parameters for the desired algorithm\n",
    "algorithm_name = \"SAC\"  # or \"TD3\"\n",
    "algorithm_params = config[algorithm_name]\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=feature_extractor,\n",
    "    net_arch = config['common']['net_arch']\n",
    ")\n",
    "\n",
    "# Create the model based on the algorithm name and parameters\n",
    "if algorithm_name == \"SAC\":\n",
    "    model = SAC(env=env,\n",
    "                policy = chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                device=device, \n",
    "                **algorithm_params)\n",
    "\n",
    "elif algorithm_name == \"PPO\":\n",
    "    model = PPO(env=env, \n",
    "                policy = chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                device = device, \n",
    "                **algorithm_params)\n",
    "\n",
    "elif algorithm_name == \"TD3\":\n",
    "    # Create the action noise object\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "    action_noise_params = algorithm_params.pop(\"action_noise\")\n",
    "    action_noise = NormalActionNoise(mean=action_noise_params[\"mean\"] * np.ones(n_actions),\n",
    "                                     sigma=action_noise_params[\"sigma\"] * np.ones(n_actions))\n",
    "    model = TD3(env=env,\n",
    "                policy =chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                action_noise=action_noise,\n",
    "                device=device, \n",
    "                **algorithm_params)\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create the tb_log_name string\n",
    "tb_log_name = f\"{algorithm_name}_{current_datetime}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a checkpoint every 1000 steps\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=5000//num_cpu,\n",
    "  save_path=\"./checkpoints/\",\n",
    "  name_prefix=tb_log_name,\n",
    "  save_replay_buffer=True,\n",
    "  save_vecnormalize=True,\n",
    ")\n",
    "\n",
    "eval_callback = EvalCallback(eval_env,\n",
    "                             log_path='tb_logs',\n",
    "                             eval_freq=5000//num_cpu,\n",
    "                             deterministic=True,\n",
    "                            n_eval_episodes=10,\n",
    "                             render=False,\n",
    "                             best_model_save_path='./checkpoints',\n",
    "                             verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "callback_list = CallbackList([eval_callback,\n",
    "                         checkpoint_callback,\n",
    "                         MaxRewardCallback(verbose=1),\n",
    "                         GradientNormCallback(verbose=1),\n",
    "                         FigureRecorderCallback(check_freq=5000//num_cpu,eval_env=eval_env)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f70cf1-e15e-4fed-ab75-12bdca996f2d",
   "metadata": {},
   "source": [
    "--- \n",
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a84e3f",
   "metadata": {},
   "source": [
    "Save the model:\n",
    "\n",
    "If model is on-policy:\n",
    "#model.save(\"sac_pendulum\")\n",
    "#loaded_model = SAC.load(\"sac_pendulum\")\n",
    "\n",
    "if model is off-policy, we also need to save the replay buffer:\n",
    "#model.save_replay_buffer(\"sac_replay_buffer\")\n",
    "#loaded_model.load_replay_buffer(\"sac_replay_buffer\")\n",
    "\n",
    "If the environment is normalized:\n",
    "#env.save('env_saved.pkl')\n",
    "#env = VecNormalize.load('env_saved.pkl',env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d7768-b7bb-4c14-b620-28a278392b6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = SAC.load(\"checkpoints/imitation_SAC\",env =env) #Saved model is with soft volume constraint and 75 r\n",
    "model.set_parameters(\"checkpoints/imitation_SACfinal.zip\")\n",
    "#print(model.batch_size)\n",
    "#model.load_replay_buffer(\"sac_replay_buffer\")\n",
    "model.learn(20000000,\n",
    "            callback=callback_list, \n",
    "            tb_log_name=tb_log_name\n",
    "            )\n",
    "#model.save('model_saved_march15',)\n",
    "#model.save_replay_buffer(\"sac_replay_buffer_march15\")\n",
    "\n",
    "#env.save('env_saved.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827c8cc-028d-4448-b109-d6542816df2a",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's visualize the agent's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728408e-71c2-4f7b-a8f1-f0cc6b43dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=sogym(mode='train',observation_type='image',vol_constraint_type='hard' ,resolution = 50)\n",
    "#env= make_vec_env(lambda:env, n_envs=1,vec_env_cls=SubprocVecEnv)\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbb153d-80e3-4d6c-ada3-f4d323360b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs,info=env.reset()\n",
    "dones=False\n",
    "saved_conditions = env.conditions\n",
    "saved_nelx, saved_nely = env.nelx, env.nely\n",
    "saved_dx, saved_dy = env.dx, env.dy\n",
    "#use deepcopy to save \n",
    "while dones== False:\n",
    "    action, _states = model.predict(obs,deterministic=True)\n",
    "    print(action)\n",
    "    obs, rewards, dones,truncated, info = env.step(action)\n",
    "print(\"Desired volume:\",saved_conditions['volfrac'],\"Obtained volume:\",env.volume)\n",
    "#print(\"Env reward:\",rewards, \"Compliance:\",np.exp(1/rewards))\n",
    "env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2de1f-dd90-40b2-acc9-b3227fd2888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xval, f0val,it, H, Phimax, allPhi, den, N, cfg = run_mmc(saved_conditions,saved_nelx,saved_nely,saved_dx,saved_dy,plotting='contour')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb3_update",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

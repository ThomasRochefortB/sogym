{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e6157f-d831-41f7-b27c-f949e2253f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB3 version: 2.2.1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'       #Disactivate multiprocessing for numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize, SubprocVecEnv\n",
    "from stable_baselines3 import PPO, A2C, SAC, TD3\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList, CheckpointCallback\n",
    "\n",
    "from sogym.env import sogym\n",
    "from sogym.mmc_optim import run_mmc\n",
    "from sogym.env import sogym\n",
    "from sogym.expert_generation import generate_expert_dataset, generate_mmc_solutions, generate_dataset\n",
    "from sogym.utils import profile_and_analyze,ImageDictExtractor, CustomBoxDense\n",
    "from sogym.callbacks import FigureRecorderCallback, MaxRewardCallback, GradientNormCallback\n",
    "from sogym.pretraining import pretrain_agent, ExpertDataSet\n",
    "\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import random_split, Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print('SB3 version:', stable_baselines3.__version__)\n",
    "# Let's make the code device agnostic:\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b8cad-4629-49cf-a15e-ebb7c9a5b6c1",
   "metadata": {},
   "source": [
    "---\n",
    "### Environment test and visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a4374a-b735-4474-8427-30b1d55dfe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's test the environment using the check_env util from SB3:\n",
    "observation_type = 'image'\n",
    "train_env = sogym(mode='train',observation_type=observation_type,vol_constraint_type='hard',resolution=50,check_connectivity = True)\n",
    "eval_env = sogym(mode='test',observation_type=observation_type,vol_constraint_type='hard',resolution=50,check_connectivity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27032137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46374828  0.81207687 -0.8963759   0.7595936   0.9416236   0.7277135 ]\n",
      "[-0.30606973 -0.0491755  -0.760215    0.8483492  -0.9363419  -0.36094844]\n",
      "[ 0.7344511  -0.24158916 -0.8847978   0.06316704  0.28622296 -0.8546042 ]\n",
      "[ 0.93793046  0.41832328 -0.82537097  0.21243857  0.82969147  0.24925756]\n",
      "[-0.98316324 -0.10443714 -0.8899654   0.09276891  0.11732262 -0.3910789 ]\n",
      "[ 0.74293405 -0.6692614  -0.3266315  -0.7247944  -0.81826353  0.5445791 ]\n",
      "[-0.43612888  0.48251918  0.7253474   0.92227745  0.45133823 -0.08856352]\n",
      "[-0.0593651   0.6110155  -0.8679693  -0.19620202 -0.44162685  0.10002508]\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs,info=train_env.reset()\n",
    "dones = False\n",
    "#use deepcopy to save \n",
    "while dones== False:\n",
    "    action = train_env.action_space.sample()\n",
    "    print(action)\n",
    "    obs, rewards, dones,truncated, info = train_env.step(action)\n",
    "print(rewards)\n",
    "train_env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6edcde2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# It will check your custom environment and output additional warnings if needed\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcheck_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43msogym\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mobservation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/common/env_checker.py:461\u001b[0m, in \u001b[0;36mcheck_env\u001b[0;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# ============ Check the returned values ===============\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m \u001b[43m_check_returned_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# ==== Check the render method and the declared render modes ====\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_render_check:\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/common/env_checker.py:292\u001b[0m, in \u001b[0;36m_check_returned_values\u001b[0;34m(env, observation_space, action_space)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# Sample a random action\u001b[39;00m\n\u001b[1;32m    291\u001b[0m action \u001b[38;5;241m=\u001b[39m action_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m--> 292\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m, (\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `step()` method must return five values: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs, reward, terminated, truncated, info. Actual: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m values returned.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m )\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Unpack\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/thomas/GitHub/sogym_v2/sogym/env.py:234\u001b[0m, in \u001b[0;36msogym.step\u001b[0;34m(self, action, evaluate)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    233\u001b[0m     terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_compliance_and_stress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_connected\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# At the end of the episode\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/thomas/GitHub/sogym_v2/sogym/env.py:253\u001b[0m, in \u001b[0;36msogym.calculate_compliance_and_stress\u001b[0;34m(self, is_connected)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_compliance_and_stress\u001b[39m(\u001b[38;5;28mself\u001b[39m, is_connected):\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompliance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mF \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_compliance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnelx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnely\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_connected:\n\u001b[1;32m    257\u001b[0m         nDof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/scratch/thomas/GitHub/sogym_v2/sogym/struct.py:110\u001b[0m, in \u001b[0;36mcalculate_compliance\u001b[0;34m(H, conditions, DW, DH, nelx, nely)\u001b[0m\n\u001b[1;32m    108\u001b[0m K \u001b[38;5;241m=\u001b[39m csc_matrix((sK\u001b[38;5;241m.\u001b[39mflatten(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m), (Iar0[:,\u001b[38;5;241m0\u001b[39m], Iar0[:,\u001b[38;5;241m1\u001b[39m])), shape\u001b[38;5;241m=\u001b[39m(nDof, nDof))\n\u001b[1;32m    109\u001b[0m K \u001b[38;5;241m=\u001b[39m  K \u001b[38;5;241m+\u001b[39m K\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m-\u001b[39m diags((K\u001b[38;5;241m.\u001b[39mdiagonal()))\n\u001b[0;32m--> 110\u001b[0m U[freeDof] \u001b[38;5;241m=\u001b[39m\u001b[43mspsolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfreeDof\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfreeDof\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfreeDof\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(freeDof),\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    112\u001b[0m f0val \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m*\u001b[39mU\n\u001b[1;32m    114\u001b[0m Comp\u001b[38;5;241m=\u001b[39mf0val\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:273\u001b[0m, in \u001b[0;36mspsolve\u001b[0;34m(A, b, permc_spec, use_umfpack)\u001b[0m\n\u001b[1;32m    270\u001b[0m     flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# CSR format\u001b[39;00m\n\u001b[1;32m    272\u001b[0m options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ColPerm\u001b[38;5;241m=\u001b[39mpermc_spec)\n\u001b[0;32m--> 273\u001b[0m x, info \u001b[38;5;241m=\u001b[39m \u001b[43m_superlu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgssv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    276\u001b[0m     warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrix is exactly singular\u001b[39m\u001b[38;5;124m\"\u001b[39m, MatrixRankWarning)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# It will check your custom environment and output additional warnings if needed\n",
    "check_env(sogym(mode='train',observation_type='image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de06f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Function Path</th>\n",
       "      <th>ncalls</th>\n",
       "      <th>tottime</th>\n",
       "      <th>percall (tottime)</th>\n",
       "      <th>cumtime</th>\n",
       "      <th>percall (cumtime)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>/scratch/thomas/GitHub/sogym_v2/sogym/utils.py...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>1.416293e-03</td>\n",
       "      <td>24.857043</td>\n",
       "      <td>2.485704e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>/scratch/thomas/GitHub/sogym_v2/sogym/env.py:1...</td>\n",
       "      <td>160</td>\n",
       "      <td>0.026677</td>\n",
       "      <td>1.667297e-04</td>\n",
       "      <td>23.908802</td>\n",
       "      <td>1.494300e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>/scratch/thomas/GitHub/sogym_v2/sogym/env.py:2...</td>\n",
       "      <td>160</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>9.299674e-05</td>\n",
       "      <td>14.138248</td>\n",
       "      <td>8.836405e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>/scratch/thomas/GitHub/sogym_v2/sogym/struct.p...</td>\n",
       "      <td>160</td>\n",
       "      <td>0.136937</td>\n",
       "      <td>8.558544e-04</td>\n",
       "      <td>14.123368</td>\n",
       "      <td>8.827105e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>/home/thomas/anaconda3/envs/SB3_update/lib/pyt...</td>\n",
       "      <td>160</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>1.637755e-05</td>\n",
       "      <td>12.141764</td>\n",
       "      <td>7.588602e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>~:0(&lt;built-in method builtins.id&gt;)</td>\n",
       "      <td>331152</td>\n",
       "      <td>0.028034</td>\n",
       "      <td>8.465653e-08</td>\n",
       "      <td>0.028034</td>\n",
       "      <td>8.465653e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>~:0(&lt;built-in method math.factorial&gt;)</td>\n",
       "      <td>17820</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>8.215561e-08</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>8.215561e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>~:0(&lt;method 'items' of 'dict' objects&gt;)</td>\n",
       "      <td>920223</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>8.214738e-08</td>\n",
       "      <td>0.075594</td>\n",
       "      <td>8.214738e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>~:0(&lt;built-in method builtins.callable&gt;)</td>\n",
       "      <td>117688</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>8.044547e-08</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>8.044547e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>~:0(&lt;method 'rstrip' of 'str' objects&gt;)</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>7.890909e-08</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>7.890909e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1386 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Full Function Path  ncalls   tottime  \\\n",
       "126   /scratch/thomas/GitHub/sogym_v2/sogym/utils.py...       1  0.001416   \n",
       "218   /scratch/thomas/GitHub/sogym_v2/sogym/env.py:1...     160  0.026677   \n",
       "219   /scratch/thomas/GitHub/sogym_v2/sogym/env.py:2...     160  0.014879   \n",
       "231   /scratch/thomas/GitHub/sogym_v2/sogym/struct.p...     160  0.136937   \n",
       "128   /home/thomas/anaconda3/envs/SB3_update/lib/pyt...     160  0.002620   \n",
       "...                                                 ...     ...       ...   \n",
       "11                   ~:0(<built-in method builtins.id>)  331152  0.028034   \n",
       "1256              ~:0(<built-in method math.factorial>)   17820  0.001464   \n",
       "81              ~:0(<method 'items' of 'dict' objects>)  920223  0.075594   \n",
       "3              ~:0(<built-in method builtins.callable>)  117688  0.009467   \n",
       "66              ~:0(<method 'rstrip' of 'str' objects>)     110  0.000009   \n",
       "\n",
       "      percall (tottime)    cumtime  percall (cumtime)  \n",
       "126        1.416293e-03  24.857043       2.485704e+01  \n",
       "218        1.667297e-04  23.908802       1.494300e-01  \n",
       "219        9.299674e-05  14.138248       8.836405e-02  \n",
       "231        8.558544e-04  14.123368       8.827105e-02  \n",
       "128        1.637755e-05  12.141764       7.588602e-02  \n",
       "...                 ...        ...                ...  \n",
       "11         8.465653e-08   0.028034       8.465653e-08  \n",
       "1256       8.215561e-08   0.001464       8.215561e-08  \n",
       "81         8.214738e-08   0.075594       8.214738e-08  \n",
       "3          8.044547e-08   0.009467       8.044547e-08  \n",
       "66         7.890909e-08   0.000009       7.890909e-08  \n",
       "\n",
       "[1386 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "# Specify the number of episodes to run\n",
    "num_episodes = 20\n",
    "# Call the profile_and_analyze function\n",
    "result_df = profile_and_analyze(num_episodes, train_env)\n",
    "# Print the resulting DataFrame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f888890",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = train_env.reset()\n",
    "cfg = {\n",
    "            'optimizer':'mma', #optimiser choice\n",
    "            'xInt':0.25, #initial interval of components in x\n",
    "            'yInt':0.25, #initial interval of components in y\n",
    "            'E':1.0, #Young's modulus\n",
    "            'nu':0.3, #Poisson ratio\n",
    "            'h':1, #thickness\n",
    "            'dgt0':5, #significant digit of sens.\n",
    "            'scl':1, #scale factor for obj\n",
    "            'p':6,  #power of super ellipsoid\n",
    "            'lmd':100, #power of KS aggregation   \n",
    "            'maxiter':500, # maximum number of outer iterations\n",
    "            'alpha':1e-9, # This is the threshold level in the Heaviside function\n",
    "            'epsilon':0.2, #This is the regularization term in the Heaviside function\n",
    "            'maxinnerinit':1, # This is the maximum number of inner iterations for GCMMA\n",
    "            'switch':-0.000002, # This is the switch criteria for the hybrid optimizer\n",
    "            'convergence_threshold':2e-4, #This is the threshold for the relative change in the objective function\n",
    "            'xmin':(0.0, 0.0, 0.0, 0.00, 0.00, -np.pi),\n",
    "            'xmax':(train_env.dx, train_env.dy, 0.7*min(train_env.dx,train_env.dy), 0.05*min(train_env.dx,train_env.dy),0.05*min(train_env.dx,train_env.dy), np.pi)\n",
    "        }\n",
    "\n",
    "#run_mmc(train_env.conditions,train_env.nelx,train_env.nely,train_env.dx,train_env.dy,plotting='contour',verbose=0,cfg=cfg)\n",
    "dataset_folder = \"/home/thomas/Documents/scratch_thomas/GitHub/sogym_v2/dataset/topologies/mmc\"\n",
    "#generate_mmc_solutions(key=0,dataset_folder=\"/home/thomas/Documents/scratch_thomas/GitHub/sogym_v2/dataset/topologies/mmc\")\n",
    "generate_dataset(dataset_folder= dataset_folder, num_threads=32, num_samples=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the training environment on a random problem statement and visualize a 'successful' solution:\n",
    "reward = 0.0\n",
    "while reward==0.0:\n",
    "    obs = train_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = train_env.action_space.sample()\n",
    "        obs, reward, done,truncated, info = train_env.step(action)\n",
    "        \n",
    "# print(\"Volume: \", train_env.volume)\n",
    "print(\"Reward \",reward)\n",
    "\n",
    "train_env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a21145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axes for the subplots\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Initialize the index for the current subplot\n",
    "subplot_index = 0\n",
    "\n",
    "# Let's visualize the training environment on a random problem statement and visualize a 'successful' solution:\n",
    "reward = 0.0\n",
    "while reward == 0.0:\n",
    "    obs = train_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = train_env.action_space.sample()\n",
    "        obs, reward, done, truncated, info = train_env.step(action)\n",
    "        \n",
    "        # Plot the current observation image\n",
    "        axes[subplot_index].imshow(obs['strain_energy'].T, cmap='gray')\n",
    "        axes[subplot_index].axis('off')\n",
    "        axes[subplot_index].set_title(f\"Timestep {subplot_index+1}\")\n",
    "        \n",
    "        # Increment the subplot index\n",
    "        subplot_index += 1\n",
    "        \n",
    "        # If all subplots are filled, display the plot and reset the index\n",
    "        if subplot_index == len(axes):\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            subplot_index = 0\n",
    "\n",
    "# Print the reward\n",
    "print(\"Reward:\", reward)\n",
    "\n",
    "# Plot the final state of the training environment\n",
    "train_env.plot()\n",
    "\n",
    "# Display any remaining subplots\n",
    "if subplot_index > 0:\n",
    "    for i in range(subplot_index, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3f4a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 40602/40602 [2:17:24<00:00,  4.93file/s]  \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Specify the number of permutations to generate\n",
    "num_permutations = 1\n",
    "observation_type = \"image\"\n",
    "\n",
    "# Specify the environment configuration (optional)\n",
    "env_kwargs = {\n",
    "    'mode': 'train',\n",
    "    'observation_type': 'image',\n",
    "    'vol_constraint_type': 'hard',\n",
    "    'seed': 42,\n",
    "    'resolution' : 50,\n",
    "    'check_connectivity':True\n",
    "}\n",
    "\n",
    "directory_path = \"/home/thomas/Documents/scratch_thomas/GitHub/sogym_v2/dataset/topologies/mmc\"\n",
    "expert_observations, expert_actions = generate_expert_dataset(directory_path,env_kwargs, plot_terminated=False,num_permutations = 5, file_fraction=1.0)\n",
    "# Save the dataset\n",
    "import pickle\n",
    "\n",
    "# Save the data using pickle\n",
    "with open('expert_dataset_image_5perm.pkl', 'wb') as f:\n",
    "    pickle.dump({'expert_observations': expert_observations, 'expert_actions': expert_actions}, f, protocol=4)\n",
    "print(len(expert_observations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae43524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the data using pickle\n",
    "with open('test.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "expert_observations = data['expert_observations']\n",
    "expert_actions = data['expert_actions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baea7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3713322/3984978650.py:14: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  axes[0].imshow(observation['image'].T, cmap='gray', origin='lower')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4176,  0.5216,  0.0645, -0.0159, -0.8737, -0.5772],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming you have the expert_dataset defined\n",
    "expert_dataset = ExpertDataSet(expert_observations, expert_actions, train_env)\n",
    "# Get a random sample from the dataset\n",
    "sample_idx = np.random.randint(len(expert_dataset))\n",
    "sample = expert_dataset[sample_idx]\n",
    "\n",
    "# Extract the observation and reward from the sample\n",
    "observation, action = sample\n",
    "\n",
    "# Subplot with image, strain_energy, and structure_strain_energy observations:\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot image observation\n",
    "axes[0].imshow(observation['image'].T, cmap='gray', origin='lower')\n",
    "axes[0].axis('on')\n",
    "axes[0].set_title(\"Image Observation\")\n",
    "\n",
    "# Plot strain_energy observation\n",
    "axes[1].imshow(observation['structure_strain_energy'].T, origin='lower')\n",
    "axes[1].axis('on')\n",
    "axes[1].set_title(\"Structure Strain Energy Observation\")\n",
    "\n",
    "print(action)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ad778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_policy = \"MlpPolicy\" if observation_type == 'box_dense' else \"MultiInputPolicy\"\n",
    "\n",
    "feature_extractor = ImageDictExtractor if observation_type == 'image' else CustomBoxDense\n",
    "\n",
    "# Load the YAML file\n",
    "env=train_env\n",
    "\n",
    "with open(\"algorithms.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Extract the parameters for the desired algorithm\n",
    "algorithm_name = \"SAC\"  # or \"TD3\"\n",
    "algorithm_params = config[algorithm_name]\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=feature_extractor,\n",
    "    net_arch = config['common']['net_arch'],\n",
    "    share_features_extractor = False\n",
    ")\n",
    "\n",
    "# Create the model based on the algorithm name and parameters\n",
    "if algorithm_name == \"SAC\":\n",
    "    model = SAC(env=env,\n",
    "                policy = chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                device=device, \n",
    "                **algorithm_params)\n",
    "\n",
    "elif algorithm_name == \"PPO\":\n",
    "    model = PPO(env=env, \n",
    "                policy = chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                device = device, \n",
    "                **algorithm_params)\n",
    "\n",
    "elif algorithm_name == \"TD3\":\n",
    "    # Create the action noise object\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "    action_noise_params = algorithm_params.pop(\"action_noise\")\n",
    "    action_noise = NormalActionNoise(mean=action_noise_params[\"mean\"] * np.ones(n_actions),\n",
    "                                     sigma=action_noise_params[\"sigma\"] * np.ones(n_actions))\n",
    "    model = TD3(env=env,\n",
    "                policy =chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                action_noise=action_noise,\n",
    "                device=device, \n",
    "                **algorithm_params)\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create the tb_log_name string\n",
    "tb_log_name = f\"{algorithm_name}_{current_datetime}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "090eedd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 46,682,128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MultiInputPolicy                         --\n",
       "├─Actor: 1-1                             --\n",
       "│    └─ImageDictExtractor: 2-1           --\n",
       "│    │    └─ReLU: 3-1                    --\n",
       "│    │    └─ModuleDict: 3-2              259,584\n",
       "│    └─Sequential: 2-2                   --\n",
       "│    │    └─Linear: 3-3                  8,651,264\n",
       "│    │    └─ReLU: 3-4                    --\n",
       "│    │    └─Linear: 3-5                  262,656\n",
       "│    │    └─ReLU: 3-6                    --\n",
       "│    │    └─Linear: 3-7                  262,656\n",
       "│    │    └─ReLU: 3-8                    --\n",
       "│    └─Linear: 2-3                       3,078\n",
       "│    └─Linear: 2-4                       3,078\n",
       "├─ContinuousCritic: 1-2                  --\n",
       "│    └─ImageDictExtractor: 2-5           --\n",
       "│    │    └─ReLU: 3-9                    --\n",
       "│    │    └─ModuleDict: 3-10             259,584\n",
       "│    └─Sequential: 2-6                   --\n",
       "│    │    └─Linear: 3-11                 8,654,336\n",
       "│    │    └─ReLU: 3-12                   --\n",
       "│    │    └─Linear: 3-13                 262,656\n",
       "│    │    └─ReLU: 3-14                   --\n",
       "│    │    └─Linear: 3-15                 262,656\n",
       "│    │    └─ReLU: 3-16                   --\n",
       "│    │    └─Linear: 3-17                 513\n",
       "│    └─Sequential: 2-7                   --\n",
       "│    │    └─Linear: 3-18                 8,654,336\n",
       "│    │    └─ReLU: 3-19                   --\n",
       "│    │    └─Linear: 3-20                 262,656\n",
       "│    │    └─ReLU: 3-21                   --\n",
       "│    │    └─Linear: 3-22                 262,656\n",
       "│    │    └─ReLU: 3-23                   --\n",
       "│    │    └─Linear: 3-24                 513\n",
       "├─ContinuousCritic: 1-3                  --\n",
       "│    └─ImageDictExtractor: 2-8           --\n",
       "│    │    └─ReLU: 3-25                   --\n",
       "│    │    └─ModuleDict: 3-26             259,584\n",
       "│    └─Sequential: 2-9                   --\n",
       "│    │    └─Linear: 3-27                 8,654,336\n",
       "│    │    └─ReLU: 3-28                   --\n",
       "│    │    └─Linear: 3-29                 262,656\n",
       "│    │    └─ReLU: 3-30                   --\n",
       "│    │    └─Linear: 3-31                 262,656\n",
       "│    │    └─ReLU: 3-32                   --\n",
       "│    │    └─Linear: 3-33                 513\n",
       "│    └─Sequential: 2-10                  --\n",
       "│    │    └─Linear: 3-34                 8,654,336\n",
       "│    │    └─ReLU: 3-35                   --\n",
       "│    │    └─Linear: 3-36                 262,656\n",
       "│    │    └─ReLU: 3-37                   --\n",
       "│    │    └─Linear: 3-38                 262,656\n",
       "│    │    └─ReLU: 3-39                   --\n",
       "│    │    └─Linear: 3-40                 513\n",
       "=================================================================\n",
       "Total params: 46,682,128\n",
       "Trainable params: 46,682,128\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "total_params = sum(p.numel() for p in model.policy.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")\n",
    "data = {k: v for k, v in observation.items()}\n",
    "# Assuming you have a PyTorch model named 'model' and the input size is (3, 224, 224)\n",
    "summary(model.policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d947adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiInputPolicy(\n",
       "  (actor): Actor(\n",
       "    (features_extractor): ImageDictExtractor(\n",
       "      (activ_func): ReLU()\n",
       "      (extractors): ModuleDict(\n",
       "        (design_variables): Sequential(\n",
       "          (0): Linear(in_features=48, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (image): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): Dropout(p=0.0, inplace=False)\n",
       "          (9): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (n_steps_left): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (score): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (structure_strain_energy): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): Dropout(p=0.0, inplace=False)\n",
       "          (9): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (volume): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (latent_pi): Sequential(\n",
       "      (0): Linear(in_features=16896, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (mu): Linear(in_features=512, out_features=6, bias=True)\n",
       "    (log_std): Linear(in_features=512, out_features=6, bias=True)\n",
       "  )\n",
       "  (critic): ContinuousCritic(\n",
       "    (features_extractor): ImageDictExtractor(\n",
       "      (activ_func): ReLU()\n",
       "      (extractors): ModuleDict(\n",
       "        (design_variables): Sequential(\n",
       "          (0): Linear(in_features=48, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (image): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): Dropout(p=0.0, inplace=False)\n",
       "          (9): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (n_steps_left): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (score): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (structure_strain_energy): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): Dropout(p=0.0, inplace=False)\n",
       "          (9): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (volume): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): Linear(in_features=16902, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): Linear(in_features=16902, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (critic_target): ContinuousCritic(\n",
       "    (features_extractor): ImageDictExtractor(\n",
       "      (activ_func): ReLU()\n",
       "      (extractors): ModuleDict(\n",
       "        (design_variables): Sequential(\n",
       "          (0): Linear(in_features=48, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (image): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): Dropout(p=0.0, inplace=False)\n",
       "          (9): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (n_steps_left): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (score): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (structure_strain_energy): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): Dropout(p=0.0, inplace=False)\n",
       "          (9): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "        (volume): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.0, inplace=False)\n",
       "          (6): Flatten(start_dim=1, end_dim=-1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): Linear(in_features=16902, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): Linear(in_features=16902, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0166b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 22:08:34.266278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-10 22:08:34.804929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/cv2/../../lib64:/local/cuda-11.3/lib64:/local/TensorRT-7.2.2.3/lib\n",
      "2024-04-10 22:08:34.805069: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/cv2/../../lib64:/local/cuda-11.3/lib64:/local/TensorRT-7.2.2.3/lib\n",
      "2024-04-10 22:08:34.805076: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch, tensorboard.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/thomasrb/pretraining-rl/a79550d72c4d41959f5ad8c5bdc89c20\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2841,  0.9899, -0.1119, -0.7013,  0.3223, -0.2827],\n",
      "        [-0.8840,  0.9819,  0.0050, -0.9922, -0.3120,  0.5928],\n",
      "        [-0.8718, -0.1034, -0.7038, -0.9148, -0.4082,  0.0115],\n",
      "        ...,\n",
      "        [-0.8470, -0.7072,  0.7407,  0.8048,  0.3844,  0.9086],\n",
      "        [-0.7270, -0.3864,  0.1392,  0.9583,  0.8978, -0.6340],\n",
      "        [-0.5593, -0.8058,  0.5764,  0.4645,  0.7364,  0.6416]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 1 [8192/129926 (6%)]\tLoss: 0.914917\tGrad Norm: 0.358479\tLR: 1.000000\n",
      "tensor([[-0.5702, -0.5460, -0.4955, -0.8894,  0.4846, -0.4969],\n",
      "        [-0.7087, -0.7169,  0.0612, -0.4439,  0.4411,  0.8313],\n",
      "        [ 0.8690,  0.0462, -0.8302,  0.7618, -0.4699,  0.9225],\n",
      "        ...,\n",
      "        [ 0.3807, -0.5742, -0.4176,  0.9167, -0.3151,  0.8240],\n",
      "        [-0.7811, -0.8588, -0.5761,  0.7133,  0.5141, -0.8474],\n",
      "        [-0.3348,  0.9179,  0.5920, -0.3693,  0.5433, -0.9543]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.5899, -0.7186,  0.7008,  0.2566,  0.5706,  0.6618],\n",
      "        [-0.5929,  0.9192,  0.3094,  0.1864,  0.5806, -0.5530],\n",
      "        [ 0.3360, -0.4732, -0.7259, -0.9309,  0.7540,  0.3477],\n",
      "        ...,\n",
      "        [-0.6540,  0.8625,  0.0755,  0.5507,  0.1413,  0.9266],\n",
      "        [ 0.0568,  0.5423, -0.2972, -0.3106,  0.1913,  0.9733],\n",
      "        [-0.9198, -0.8313, -0.9752,  0.8154, -0.7853, -0.0259]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.7938, -0.5426,  0.7650,  0.4146,  0.8854,  0.6674],\n",
      "        [-0.8583, -0.0181,  0.5346,  0.5900,  0.7562,  0.8396],\n",
      "        [-0.8613, -0.7149,  0.9423,  0.0982,  0.9090,  0.8602],\n",
      "        ...,\n",
      "        [-0.8837,  0.1074,  0.4823, -0.4076,  0.9275,  0.9177],\n",
      "        [-0.7645, -0.4684,  0.6736,  0.0539,  0.8928,  0.8277],\n",
      "        [-0.8246,  0.2594,  0.7887, -0.0432,  0.9217,  0.9416]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.8193,  0.2752,  0.5774,  0.0197,  0.7198,  0.4286],\n",
      "        [-0.8049,  0.5829,  0.5821, -0.2946,  0.7046,  0.6243],\n",
      "        [-0.9083,  0.5041,  0.5948, -0.2793,  0.8311,  0.8138],\n",
      "        ...,\n",
      "        [-0.8093,  0.2485,  0.5963, -0.3158,  0.9216,  0.5786],\n",
      "        [-0.5721,  0.3314,  0.6800, -0.2065,  0.7616,  0.8722],\n",
      "        [-0.0700,  0.4525,  0.8015, -0.1855,  0.8489,  0.8199]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.8693, -0.9298,  0.8212,  0.6478,  0.9211,  0.8460],\n",
      "        [-0.9377, -0.9225,  0.8604,  0.6389,  0.9350,  0.8763],\n",
      "        [-0.8696, -0.9004,  0.7943,  0.4812,  0.8570,  0.8117],\n",
      "        ...,\n",
      "        [-0.8992, -0.9047,  0.8789,  0.5518,  0.8812,  0.8723],\n",
      "        [-0.9285, -0.8933,  0.8448,  0.7077,  0.9129,  0.7959],\n",
      "        [-0.9005, -0.9196,  0.8871,  0.6054,  0.9002,  0.8390]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 1 [49152/129926 (38%)]\tLoss: 0.584381\tGrad Norm: 2.149785\tLR: 1.000000\n",
      "tensor([[ 0.5528,  0.0995, -0.2952, -0.3917,  0.8278,  0.2960],\n",
      "        [ 0.9092, -0.0427,  0.6973, -0.3118,  0.2392,  0.6807],\n",
      "        [-0.1584, -0.6737,  0.8516, -0.1344, -0.1472,  0.8278],\n",
      "        ...,\n",
      "        [-0.0504, -0.4955, -0.5649, -0.7062, -0.9868, -0.0524],\n",
      "        [-0.7109, -0.6467,  0.8839, -0.5067,  0.3851, -0.8089],\n",
      "        [-0.4028,  0.2730,  0.2844, -0.1598, -0.7557,  0.8604]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.1024, -0.9545,  0.1559,  0.2639, -0.1633,  0.0946],\n",
      "        [ 0.3295,  0.4920,  0.5900,  0.1163,  0.5569,  0.6708],\n",
      "        [-0.8262, -0.2261, -0.0368, -0.2061,  0.9168, -0.0227],\n",
      "        ...,\n",
      "        [-0.5933,  0.3084,  0.2715,  0.2501,  0.6930,  0.1755],\n",
      "        [-0.3858, -0.7049,  0.7136,  0.5980,  0.6386, -0.2225],\n",
      "        [ 0.3966, -0.1375, -0.5818,  0.5974,  0.2427,  0.9174]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.9882,  0.0077,  0.9608, -0.9468,  0.9962,  0.9958],\n",
      "        [-0.9838,  0.0029,  0.9517, -0.9355,  0.9944,  0.9940],\n",
      "        [-0.9908,  0.0172,  0.9684, -0.9580,  0.9972,  0.9971],\n",
      "        ...,\n",
      "        [-0.9860,  0.0288,  0.9585, -0.9453,  0.9955,  0.9956],\n",
      "        [-0.9911,  0.0086,  0.9704, -0.9601,  0.9973,  0.9973],\n",
      "        [-0.9911,  0.0067,  0.9693, -0.9598,  0.9974,  0.9973]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.8510, -0.4273,  0.4523, -0.1322,  0.9396,  0.9171],\n",
      "        [-0.8177, -0.3352,  0.4680, -0.0464,  0.9194,  0.8785],\n",
      "        [-0.8317, -0.2848,  0.4113, -0.3658,  0.9238,  0.9463],\n",
      "        ...,\n",
      "        [-0.8000, -0.4118,  0.4474, -0.3354,  0.9183,  0.9298],\n",
      "        [-0.8286, -0.3241,  0.4651, -0.1931,  0.9479,  0.9273],\n",
      "        [-0.8108, -0.2008,  0.3913, -0.2596,  0.9387,  0.9380]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.3238,  0.2611,  0.1130, -0.2634,  0.3274,  0.1107],\n",
      "        [-0.7880,  0.0020,  0.3987,  0.7875,  0.8126,  0.7180],\n",
      "        [ 0.3541,  0.3153,  0.5758, -0.3429,  0.7446,  0.1906],\n",
      "        ...,\n",
      "        [-0.5292, -0.0241,  0.0577, -0.3100,  0.6591,  0.7589],\n",
      "        [-0.1074,  0.4473,  0.3072,  0.7492,  0.2497,  0.0244],\n",
      "        [-0.1428, -0.6769, -0.0700,  0.0714,  0.6029,  0.7388]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 1 [90112/129926 (69%)]\tLoss: 0.478423\tGrad Norm: 1.067548\tLR: 1.000000\n",
      "tensor([[-0.9861,  0.6137,  0.9830,  0.4409,  0.9985,  0.9985],\n",
      "        [-0.9881,  0.6241,  0.9853,  0.4475,  0.9988,  0.9988],\n",
      "        [-0.9876,  0.6253,  0.9847,  0.4387,  0.9988,  0.9987],\n",
      "        ...,\n",
      "        [-0.9812,  0.5933,  0.9781,  0.4110,  0.9978,  0.9977],\n",
      "        [-0.9866,  0.6178,  0.9835,  0.4360,  0.9987,  0.9986],\n",
      "        [-0.9837,  0.5957,  0.9794,  0.4137,  0.9981,  0.9979]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.5862, -0.7273,  0.5513, -0.6832,  0.8867,  0.8217],\n",
      "        [-0.5662, -0.7331,  0.7052, -0.7531,  0.7492,  0.8270],\n",
      "        [-0.7104, -0.7397,  0.6149, -0.7632,  0.9085,  0.7816],\n",
      "        ...,\n",
      "        [-0.5040, -0.6963,  0.6357, -0.5910,  0.8713,  0.7983],\n",
      "        [-0.6049, -0.7140,  0.6600, -0.7111,  0.7938,  0.6592],\n",
      "        [-0.5013, -0.7424,  0.5756, -0.5883,  0.8007,  0.8650]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.1627,  0.1076,  0.3943, -0.1010,  0.8610,  0.3737],\n",
      "        [-0.2188, -0.1225,  0.8417, -0.3235,  0.0817,  0.0818],\n",
      "        [-0.1558, -0.2230, -0.7532, -0.2239,  0.3439, -0.5700],\n",
      "        ...,\n",
      "        [ 0.3276,  0.7442,  0.4244,  0.8821, -0.0841,  0.3205],\n",
      "        [-0.2002, -0.6341,  0.0340,  0.1749, -0.2162,  0.4031],\n",
      "        [-0.6271, -0.6956, -0.4674,  0.1307,  0.6925,  0.4657]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.5963, -0.0617,  0.5874, -0.1030,  0.5557,  0.7207],\n",
      "        [-0.2139, -0.4607,  0.4229, -0.0188,  0.5218,  0.5261],\n",
      "        [-0.2602, -0.5180, -0.3403,  0.0115,  0.7771,  0.6334],\n",
      "        ...,\n",
      "        [-0.4690, -0.0185,  0.3513, -0.0487,  0.7480,  0.7404],\n",
      "        [-0.4813,  0.0286,  0.6877, -0.7981,  0.2589,  0.7345],\n",
      "        [-0.6742,  0.1047,  0.4956,  0.2668,  0.5106,  0.4486]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.7199, -0.1896,  0.7780, -0.3376,  0.9283,  0.8923],\n",
      "        [-0.7581, -0.1844,  0.6910, -0.0037,  0.8587,  0.8874],\n",
      "        [-0.7726, -0.2410,  0.7619, -0.1244,  0.9389,  0.9401],\n",
      "        ...,\n",
      "        [-0.8502, -0.2746,  0.7609, -0.4171,  0.9129,  0.8957],\n",
      "        [-0.7736, -0.1361,  0.7040, -0.2282,  0.8966,  0.8807],\n",
      "        [-0.7848, -0.2803,  0.7183, -0.4283,  0.9258,  0.9273]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 1 [131072/129926 (100%)]\tLoss: 0.400127\tGrad Norm: 0.876657\tLR: 1.000000\n",
      "Train set: Average loss: 0.5844\n",
      "Test set: Average loss: 0.3907\n",
      "Saved best model to checkpoints/imitation_SAC\n",
      "tensor([[-0.4348,  0.4039,  0.7076,  0.3253,  0.4787,  0.5431],\n",
      "        [-0.4360,  0.0149,  0.5383, -0.0425,  0.8763,  0.8097],\n",
      "        [-0.2784,  0.2917,  0.6442, -0.0405,  0.0842,  0.4900],\n",
      "        ...,\n",
      "        [-0.6430,  0.4604,  0.2811,  0.1761,  0.8159,  0.1873],\n",
      "        [-0.1223,  0.3025,  0.5141,  0.2939,  0.6560,  0.3586],\n",
      "        [-0.5492,  0.1523,  0.0747,  0.2610,  0.8284,  0.8107]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 2 [8192/129926 (6%)]\tLoss: 0.392003\tGrad Norm: 0.610389\tLR: 0.980000\n",
      "tensor([[-0.7824, -0.0363,  0.7181, -0.0856,  0.8996,  0.9031],\n",
      "        [-0.7595,  0.0664,  0.7399,  0.1201,  0.9272,  0.9116],\n",
      "        [-0.7484, -0.0628,  0.6625, -0.0639,  0.9048,  0.9043],\n",
      "        ...,\n",
      "        [-0.7799, -0.0455,  0.7433,  0.0158,  0.9064,  0.9200],\n",
      "        [-0.7592, -0.1130,  0.7790, -0.0209,  0.8992,  0.8930],\n",
      "        [-0.7780,  0.0130,  0.7092,  0.0662,  0.9290,  0.9168]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.0811, -0.0505,  0.3582, -0.3286,  0.6779,  0.6934],\n",
      "        [-0.4934,  0.0854,  0.3924,  0.1082,  0.8192,  0.5768],\n",
      "        [-0.5201,  0.0204,  0.1440, -0.0658,  0.7404,  0.5951],\n",
      "        ...,\n",
      "        [-0.4448,  0.1023,  0.0179,  0.0610,  0.7485,  0.7438],\n",
      "        [-0.4662, -0.0131,  0.2454, -0.0358,  0.7670,  0.7726],\n",
      "        [-0.1247, -0.0268,  0.3314, -0.2017,  0.6763,  0.7549]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6756,  0.0041,  0.6112,  0.0268,  0.7034,  0.7895],\n",
      "        [-0.6134,  0.1337,  0.6886,  0.0157,  0.8358,  0.8149],\n",
      "        [-0.5770,  0.0937,  0.6367, -0.0462,  0.7688,  0.7400],\n",
      "        ...,\n",
      "        [-0.6723, -0.0025,  0.6232, -0.0729,  0.8433,  0.7178],\n",
      "        [-0.8049,  0.1147,  0.5848, -0.0947,  0.8032,  0.7823],\n",
      "        [-0.6687,  0.0102,  0.5618,  0.0748,  0.7343,  0.7848]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.4249,  0.1261,  0.3062,  0.0777,  0.3790,  0.7703],\n",
      "        [-0.4565, -0.0018,  0.3606, -0.0677,  0.6386,  0.4453],\n",
      "        [-0.4315,  0.0242,  0.4049,  0.4029,  0.6116,  0.5680],\n",
      "        ...,\n",
      "        [-0.5820, -0.1215,  0.1306, -0.0178,  0.5543,  0.7389],\n",
      "        [-0.1376, -0.1905, -0.0138,  0.0788,  0.3998,  0.3699],\n",
      "        [-0.2735,  0.0233,  0.0685, -0.0524,  0.6095,  0.4847]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.7344, -0.0156,  0.6898, -0.0359,  0.8052,  0.8516],\n",
      "        [-0.7417, -0.0127,  0.6682, -0.0658,  0.7706,  0.8153],\n",
      "        [-0.7230,  0.0381,  0.7197, -0.0281,  0.8570,  0.7957],\n",
      "        ...,\n",
      "        [-0.7279,  0.0121,  0.7000, -0.0473,  0.8532,  0.8324],\n",
      "        [-0.7044,  0.0201,  0.6885,  0.0826,  0.8366,  0.8491],\n",
      "        [-0.6427, -0.0430,  0.6677, -0.0171,  0.7905,  0.8181]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 2 [49152/129926 (38%)]\tLoss: 0.355016\tGrad Norm: 0.496112\tLR: 0.980000\n",
      "tensor([[-0.1052, -0.0491,  0.3252,  0.2062,  0.7305,  0.6877],\n",
      "        [-0.2494,  0.1026,  0.3875,  0.1941,  0.6763,  0.4676],\n",
      "        [-0.0040, -0.0198,  0.0357,  0.2652,  0.4305,  0.4498],\n",
      "        ...,\n",
      "        [-0.5439,  0.0288,  0.2754,  0.0245,  0.5778,  0.6326],\n",
      "        [-0.1356,  0.0967,  0.3284,  0.0245,  0.4047,  0.6127],\n",
      "        [-0.2382,  0.1058,  0.1721, -0.1980,  0.5420,  0.6923]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.7666, -0.1221,  0.7257, -0.0722,  0.8236,  0.8095],\n",
      "        [-0.7711, -0.0105,  0.7175,  0.0635,  0.8221,  0.8497],\n",
      "        [-0.7161, -0.0139,  0.7318,  0.0703,  0.7801,  0.8243],\n",
      "        ...,\n",
      "        [-0.7473,  0.0562,  0.7072,  0.0791,  0.8015,  0.8163],\n",
      "        [-0.7488, -0.0865,  0.6965, -0.0439,  0.7845,  0.8293],\n",
      "        [-0.7302,  0.0350,  0.7390, -0.0160,  0.8053,  0.8142]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.2502,  0.0306,  0.2081,  0.0281,  0.5244,  0.4969],\n",
      "        [-0.4044, -0.1501,  0.4175,  0.1409,  0.4855,  0.6505],\n",
      "        [-0.2760,  0.1560,  0.3806,  0.2530,  0.3774,  0.5094],\n",
      "        ...,\n",
      "        [-0.2108,  0.0739,  0.3143, -0.2404,  0.4710,  0.7197],\n",
      "        [-0.5692,  0.0659,  0.3696, -0.0566,  0.4521,  0.5721],\n",
      "        [-0.3722,  0.0913,  0.2106, -0.0474,  0.5524,  0.6318]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.7009, -0.0150,  0.6857, -0.1200,  0.8016,  0.8399],\n",
      "        [-0.6832, -0.0370,  0.7019,  0.0106,  0.8150,  0.7911],\n",
      "        [-0.6482,  0.0035,  0.7553, -0.0463,  0.8131,  0.8388],\n",
      "        ...,\n",
      "        [-0.6959,  0.0051,  0.6838, -0.0435,  0.8401,  0.8214],\n",
      "        [-0.6776,  0.0401,  0.7142,  0.0029,  0.8063,  0.8203],\n",
      "        [-0.7335,  0.0942,  0.7063, -0.0131,  0.8503,  0.7929]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.2795, -0.0009,  0.2220,  0.1126,  0.4834,  0.4200],\n",
      "        [-0.1842,  0.0928,  0.3494,  0.1766,  0.5392,  0.5062],\n",
      "        [-0.2038, -0.1125,  0.2217, -0.1771,  0.6291,  0.4790],\n",
      "        ...,\n",
      "        [-0.1538, -0.2050,  0.1328,  0.0398,  0.6266,  0.5161],\n",
      "        [-0.3706,  0.0271,  0.4190, -0.1428,  0.6358,  0.5467],\n",
      "        [-0.3858, -0.0644,  0.2190,  0.0461,  0.5292,  0.3876]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 2 [90112/129926 (69%)]\tLoss: 0.343170\tGrad Norm: 0.487845\tLR: 0.980000\n",
      "tensor([[-0.7105,  0.0295,  0.6919, -0.0772,  0.8114,  0.7581],\n",
      "        [-0.7035,  0.0809,  0.7106, -0.0736,  0.7863,  0.8084],\n",
      "        [-0.6732, -0.0192,  0.6968, -0.0171,  0.7922,  0.7935],\n",
      "        ...,\n",
      "        [-0.6999,  0.0456,  0.7148,  0.0066,  0.7913,  0.7641],\n",
      "        [-0.7379,  0.0437,  0.7267,  0.0121,  0.8008,  0.8211],\n",
      "        [-0.7512,  0.0116,  0.7189,  0.0100,  0.8122,  0.7861]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.1795,  0.0661,  0.3211,  0.0733,  0.5847,  0.6892],\n",
      "        [-0.3330,  0.0828,  0.3857,  0.0637,  0.5578,  0.5034],\n",
      "        [-0.4995,  0.0318,  0.2811, -0.0054,  0.6346,  0.5820],\n",
      "        ...,\n",
      "        [-0.3356, -0.0976,  0.3030, -0.1241,  0.4785,  0.7198],\n",
      "        [-0.4349, -0.0867,  0.4097, -0.0242,  0.6076,  0.6571],\n",
      "        [-0.4669,  0.0706,  0.4013, -0.1296,  0.6371,  0.5687]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-7.2362e-01,  1.4501e-02,  6.9264e-01,  9.8979e-02,  8.0055e-01,\n",
      "          7.8269e-01],\n",
      "        [-6.8330e-01, -2.0913e-02,  6.5399e-01,  1.7718e-02,  7.6497e-01,\n",
      "          8.0972e-01],\n",
      "        [-7.0568e-01,  2.9413e-02,  6.7624e-01, -4.8857e-02,  7.8045e-01,\n",
      "          7.6347e-01],\n",
      "        ...,\n",
      "        [-7.3845e-01,  3.8882e-03,  6.6576e-01, -3.8715e-02,  8.1532e-01,\n",
      "          7.7332e-01],\n",
      "        [-6.7939e-01, -1.7679e-02,  6.9440e-01, -3.9931e-04,  7.7358e-01,\n",
      "          7.9222e-01],\n",
      "        [-6.7448e-01,  3.7135e-02,  6.8060e-01, -1.2845e-02,  7.7714e-01,\n",
      "          7.9436e-01]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.3139, -0.0815,  0.2101,  0.1271,  0.4951,  0.6375],\n",
      "        [-0.2230, -0.1354,  0.3424, -0.0966,  0.5714,  0.6429],\n",
      "        [-0.2290,  0.0604,  0.2662, -0.0785,  0.5474,  0.6048],\n",
      "        ...,\n",
      "        [-0.2640, -0.0756,  0.1744,  0.0669,  0.5325,  0.6131],\n",
      "        [-0.3072, -0.1306,  0.2940,  0.0868,  0.6590,  0.5468],\n",
      "        [-0.3872, -0.0143,  0.2725,  0.0513,  0.5321,  0.6252]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6970, -0.0459,  0.7024,  0.0109,  0.7905,  0.7687],\n",
      "        [-0.7256,  0.0581,  0.7022,  0.0117,  0.7739,  0.8017],\n",
      "        [-0.7577,  0.0102,  0.7017, -0.0070,  0.8303,  0.7907],\n",
      "        ...,\n",
      "        [-0.7393, -0.0211,  0.7119, -0.0357,  0.7717,  0.8115],\n",
      "        [-0.7346,  0.0686,  0.6855,  0.0315,  0.7795,  0.8156],\n",
      "        [-0.7196, -0.0273,  0.7005,  0.0268,  0.8297,  0.8210]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 2 [131072/129926 (100%)]\tLoss: 0.345249\tGrad Norm: 0.436143\tLR: 0.980000\n",
      "Train set: Average loss: 0.3507\n",
      "Test set: Average loss: 0.3377\n",
      "Saved best model to checkpoints/imitation_SAC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fd50af0f490>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4298, -0.0354,  0.4389, -0.0788,  0.4361,  0.4184],\n",
      "        [-0.3526, -0.0398,  0.3184, -0.1384,  0.4266,  0.6854],\n",
      "        [-0.2530, -0.0849,  0.3919, -0.0329,  0.5076,  0.4491],\n",
      "        ...,\n",
      "        [-0.4872, -0.0748,  0.2188,  0.0158,  0.6190,  0.2025],\n",
      "        [-0.3279, -0.0331,  0.2094,  0.0010,  0.4178,  0.6123],\n",
      "        [-0.1799, -0.0579,  0.2009, -0.1384,  0.5377,  0.4605]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 3 [8192/129926 (6%)]\tLoss: 0.339540\tGrad Norm: 0.424051\tLR: 0.960400\n",
      "tensor([[-6.9404e-01, -8.8439e-02,  6.3611e-01, -7.8812e-02,  7.6198e-01,\n",
      "          8.1670e-01],\n",
      "        [-7.2082e-01,  9.8933e-03,  7.0060e-01,  4.0193e-04,  7.8266e-01,\n",
      "          7.9262e-01],\n",
      "        [-6.7460e-01,  2.7420e-02,  6.5084e-01, -9.0887e-03,  8.0100e-01,\n",
      "          8.1774e-01],\n",
      "        ...,\n",
      "        [-6.8666e-01,  3.7013e-02,  6.6980e-01, -2.0641e-02,  7.8435e-01,\n",
      "          8.1384e-01],\n",
      "        [-7.0578e-01, -3.9583e-03,  6.4691e-01,  2.7749e-02,  7.5734e-01,\n",
      "          8.0379e-01],\n",
      "        [-6.0734e-01,  4.0336e-02,  6.3862e-01, -3.0303e-02,  8.1623e-01,\n",
      "          7.6653e-01]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.5207, -0.0121,  0.3263, -0.0401,  0.6219,  0.5265],\n",
      "        [-0.3608, -0.1018,  0.2864, -0.0484,  0.4124,  0.6296],\n",
      "        [-0.4888, -0.0676,  0.3486, -0.1390,  0.6111,  0.5686],\n",
      "        ...,\n",
      "        [-0.3084,  0.0802,  0.3422, -0.0694,  0.5963,  0.4475],\n",
      "        [-0.3637, -0.0287,  0.3342, -0.0654,  0.4482,  0.5147],\n",
      "        [-0.3233,  0.0556,  0.3557, -0.0456,  0.5354,  0.6637]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.7150,  0.0116,  0.6002,  0.0157,  0.7264,  0.7461],\n",
      "        [-0.6458,  0.0100,  0.6922,  0.0172,  0.7473,  0.7592],\n",
      "        [-0.7139, -0.0032,  0.6722, -0.0158,  0.7790,  0.7827],\n",
      "        ...,\n",
      "        [-0.7118, -0.0086,  0.7014,  0.0347,  0.8193,  0.8007],\n",
      "        [-0.7222,  0.0222,  0.6459, -0.0118,  0.7963,  0.7877],\n",
      "        [-0.6629,  0.0204,  0.6847,  0.0630,  0.7527,  0.7535]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.4478, -0.0534,  0.2396, -0.0519,  0.6845,  0.6112],\n",
      "        [-0.2743, -0.0768,  0.4121,  0.0899,  0.5987,  0.6031],\n",
      "        [-0.3317, -0.1218,  0.3739, -0.1041,  0.6004,  0.4812],\n",
      "        ...,\n",
      "        [-0.2461, -0.1607,  0.3287,  0.0124,  0.7164,  0.6802],\n",
      "        [-0.3434, -0.1022,  0.4029,  0.0323,  0.5645,  0.6788],\n",
      "        [-0.3817, -0.0695,  0.3342,  0.1253,  0.6059,  0.5135]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6640,  0.0259,  0.6714, -0.0134,  0.7736,  0.8063],\n",
      "        [-0.7144,  0.0670,  0.6490, -0.0061,  0.8287,  0.7599],\n",
      "        [-0.6989, -0.0204,  0.6209, -0.0095,  0.7511,  0.7940],\n",
      "        ...,\n",
      "        [-0.6271,  0.0381,  0.6610,  0.1128,  0.7699,  0.7665],\n",
      "        [-0.6284, -0.0340,  0.6151, -0.0345,  0.7227,  0.8022],\n",
      "        [-0.6425,  0.0131,  0.6141, -0.0349,  0.7691,  0.7727]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 3 [49152/129926 (38%)]\tLoss: 0.339754\tGrad Norm: 0.389019\tLR: 0.960400\n",
      "tensor([[-0.2849,  0.0868,  0.2737, -0.0674,  0.6102,  0.4125],\n",
      "        [-0.5180, -0.0680,  0.4135, -0.1554,  0.5699,  0.6027],\n",
      "        [-0.4932,  0.0245,  0.2775,  0.1005,  0.5023,  0.6228],\n",
      "        ...,\n",
      "        [-0.2243, -0.1293,  0.0990, -0.1138,  0.6018,  0.5965],\n",
      "        [-0.2270, -0.0480,  0.3775, -0.0937,  0.5597,  0.5129],\n",
      "        [-0.3493, -0.0292,  0.2152, -0.0101,  0.5091,  0.5479]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6798,  0.0094,  0.5969,  0.0074,  0.7980,  0.7655],\n",
      "        [-0.6153,  0.0615,  0.6239,  0.0268,  0.7566,  0.7543],\n",
      "        [-0.6864,  0.0816,  0.6285,  0.0258,  0.7463,  0.7832],\n",
      "        ...,\n",
      "        [-0.6839,  0.0491,  0.6475,  0.0331,  0.7484,  0.7604],\n",
      "        [-0.6650, -0.0027,  0.6287,  0.0170,  0.7457,  0.7697],\n",
      "        [-0.6675,  0.0607,  0.6556,  0.0448,  0.7261,  0.7720]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.3084,  0.0611,  0.4605,  0.0230,  0.4723,  0.5248],\n",
      "        [-0.3366,  0.0486,  0.4195, -0.1448,  0.5240,  0.5665],\n",
      "        [-0.4021,  0.0132,  0.4703, -0.1403,  0.4277,  0.5783],\n",
      "        ...,\n",
      "        [-0.2043, -0.0313,  0.2382,  0.0478,  0.4813,  0.5056],\n",
      "        [-0.2944, -0.0606,  0.4353, -0.0254,  0.4867,  0.5168],\n",
      "        [-0.4033, -0.0241,  0.3627, -0.1394,  0.5477,  0.5048]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6576,  0.0054,  0.5849, -0.0649,  0.7535,  0.7838],\n",
      "        [-0.6725,  0.0103,  0.6355, -0.0632,  0.7141,  0.7686],\n",
      "        [-0.6669, -0.0128,  0.6376, -0.0242,  0.7715,  0.7855],\n",
      "        ...,\n",
      "        [-0.6986,  0.0289,  0.6245, -0.0156,  0.7698,  0.7638],\n",
      "        [-0.6666,  0.0374,  0.6686,  0.0064,  0.7692,  0.7962],\n",
      "        [-0.6937,  0.0455,  0.5995, -0.0568,  0.7777,  0.8039]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.5023, -0.0291,  0.3988,  0.0160,  0.6745,  0.5321],\n",
      "        [-0.3620,  0.0401,  0.3678,  0.0413,  0.5943,  0.5985],\n",
      "        [-0.5123,  0.0033,  0.3863, -0.0445,  0.6248,  0.6509],\n",
      "        ...,\n",
      "        [-0.3336,  0.0768,  0.2749, -0.0912,  0.6681,  0.6451],\n",
      "        [-0.2683, -0.0898,  0.3204, -0.0646,  0.6164,  0.5439],\n",
      "        [-0.1799, -0.0844,  0.3696, -0.0557,  0.6124,  0.4718]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 3 [90112/129926 (69%)]\tLoss: 0.329808\tGrad Norm: 0.332903\tLR: 0.960400\n",
      "tensor([[-6.3941e-01,  3.0948e-05,  6.6011e-01, -2.2874e-02,  7.8855e-01,\n",
      "          7.4069e-01],\n",
      "        [-6.1347e-01, -6.2713e-03,  6.5202e-01,  7.9856e-02,  7.4889e-01,\n",
      "          7.7126e-01],\n",
      "        [-6.0991e-01, -1.4176e-02,  6.5272e-01,  1.5966e-02,  7.2801e-01,\n",
      "          7.2383e-01],\n",
      "        ...,\n",
      "        [-6.2505e-01, -8.7026e-02,  6.5139e-01,  3.9005e-02,  7.4515e-01,\n",
      "          7.3628e-01],\n",
      "        [-5.8182e-01, -1.3349e-02,  6.3470e-01,  1.3608e-02,  7.7781e-01,\n",
      "          7.6888e-01],\n",
      "        [-5.7676e-01, -1.1772e-02,  6.3357e-01, -3.7005e-02,  7.5092e-01,\n",
      "          7.8977e-01]], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.3869, -0.0636,  0.2982, -0.0384,  0.5237,  0.5328],\n",
      "        [-0.4508, -0.0409,  0.4081,  0.0961,  0.5620,  0.5802],\n",
      "        [-0.2263,  0.0320,  0.1790,  0.0443,  0.5270,  0.4799],\n",
      "        ...,\n",
      "        [-0.3565,  0.1964,  0.3427, -0.0267,  0.5503,  0.6472],\n",
      "        [-0.4064,  0.0209,  0.4477,  0.0173,  0.5681,  0.4718],\n",
      "        [-0.2590, -0.0285,  0.4373,  0.0676,  0.4618,  0.4932]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6113, -0.0262,  0.6523, -0.1021,  0.7064,  0.6832],\n",
      "        [-0.6338, -0.0030,  0.6305,  0.1235,  0.7024,  0.7490],\n",
      "        [-0.6186,  0.0332,  0.6927, -0.0024,  0.7530,  0.7259],\n",
      "        ...,\n",
      "        [-0.6136, -0.0106,  0.6524,  0.0205,  0.7622,  0.7263],\n",
      "        [-0.5717, -0.0824,  0.6242,  0.0229,  0.7336,  0.7401],\n",
      "        [-0.6063, -0.0350,  0.6448,  0.0373,  0.7750,  0.7467]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.2934, -0.0240,  0.3547, -0.1006,  0.4244,  0.6109],\n",
      "        [-0.3292, -0.0145,  0.2963,  0.0409,  0.5293,  0.5568],\n",
      "        [-0.4822,  0.0058,  0.4156,  0.0182,  0.5823,  0.4663],\n",
      "        ...,\n",
      "        [-0.3103,  0.0802,  0.2733,  0.0591,  0.5686,  0.6789],\n",
      "        [-0.4031,  0.0269,  0.3590,  0.0447,  0.6289,  0.6023],\n",
      "        [-0.3600, -0.0327,  0.3325, -0.1168,  0.5928,  0.5054]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6132,  0.0445,  0.6080, -0.0238,  0.7350,  0.7288],\n",
      "        [-0.6756,  0.0341,  0.6313, -0.0110,  0.7857,  0.7946],\n",
      "        [-0.6420,  0.0387,  0.5982, -0.0652,  0.7503,  0.7713],\n",
      "        ...,\n",
      "        [-0.6635, -0.0098,  0.6736,  0.0190,  0.7624,  0.7666],\n",
      "        [-0.6696,  0.0210,  0.6155,  0.0027,  0.7446,  0.7770],\n",
      "        [-0.6340, -0.0060,  0.6090,  0.0189,  0.7540,  0.7913]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 3 [131072/129926 (100%)]\tLoss: 0.335802\tGrad Norm: 0.361832\tLR: 0.960400\n",
      "Train set: Average loss: 0.3354\n",
      "Test set: Average loss: 0.3328\n",
      "Saved best model to checkpoints/imitation_SAC\n",
      "tensor([[-0.3474, -0.0938,  0.3387, -0.0483,  0.5670,  0.6360],\n",
      "        [-0.2369, -0.1963,  0.4165,  0.0413,  0.5850,  0.5983],\n",
      "        [-0.3283, -0.0953,  0.2811,  0.0162,  0.6049,  0.4614],\n",
      "        ...,\n",
      "        [-0.3584, -0.1015,  0.3352, -0.0294,  0.5332,  0.4792],\n",
      "        [-0.2707, -0.0952,  0.3942,  0.0183,  0.5610,  0.5763],\n",
      "        [-0.2839, -0.0693,  0.2844, -0.0624,  0.4926,  0.5806]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 4 [8192/129926 (6%)]\tLoss: 0.334606\tGrad Norm: 0.372216\tLR: 0.941192\n",
      "tensor([[-0.6432, -0.0429,  0.5982, -0.0903,  0.7416,  0.7736],\n",
      "        [-0.6677, -0.0311,  0.6428, -0.0235,  0.7787,  0.7812],\n",
      "        [-0.6833,  0.0126,  0.5661, -0.0174,  0.7527,  0.7221],\n",
      "        ...,\n",
      "        [-0.6165,  0.0191,  0.6162,  0.0850,  0.7197,  0.7853],\n",
      "        [-0.6382,  0.0321,  0.6466, -0.0589,  0.7636,  0.7761],\n",
      "        [-0.6164,  0.0173,  0.6165, -0.0110,  0.7793,  0.7677]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.4517,  0.0620,  0.2805, -0.0659,  0.6003,  0.5617],\n",
      "        [-0.4309, -0.0125,  0.3260, -0.0157,  0.5686,  0.5248],\n",
      "        [-0.3157,  0.0090,  0.3650,  0.0133,  0.6187,  0.4547],\n",
      "        ...,\n",
      "        [-0.3936, -0.0136,  0.4764, -0.0593,  0.5089,  0.5345],\n",
      "        [-0.3794,  0.1011,  0.3897,  0.0162,  0.5691,  0.5088],\n",
      "        [-0.4156,  0.0144,  0.3344,  0.1524,  0.6291,  0.4987]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6034, -0.0615,  0.6464, -0.0060,  0.7655,  0.7555],\n",
      "        [-0.5940, -0.0193,  0.6328, -0.0046,  0.7691,  0.7491],\n",
      "        [-0.6186, -0.0391,  0.6620,  0.0281,  0.7569,  0.7727],\n",
      "        ...,\n",
      "        [-0.5718,  0.0110,  0.6195, -0.0147,  0.6933,  0.7820],\n",
      "        [-0.6665, -0.0152,  0.6198,  0.0822,  0.7020,  0.7390],\n",
      "        [-0.5557, -0.0829,  0.6293,  0.0467,  0.7486,  0.7463]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.2791,  0.0454,  0.2154,  0.0089,  0.4884,  0.5671],\n",
      "        [-0.3453, -0.0257,  0.2388,  0.0728,  0.5448,  0.5443],\n",
      "        [-0.2948,  0.0278,  0.4963,  0.0417,  0.5948,  0.4902],\n",
      "        ...,\n",
      "        [-0.5532,  0.0082,  0.3917, -0.0260,  0.5586,  0.5931],\n",
      "        [-0.3692, -0.0130,  0.3304, -0.0362,  0.6301,  0.5555],\n",
      "        [-0.4195,  0.1631,  0.3571, -0.0316,  0.4784,  0.4070]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6492,  0.0121,  0.6112,  0.0519,  0.7234,  0.7527],\n",
      "        [-0.6517,  0.0340,  0.6105, -0.0445,  0.7794,  0.7516],\n",
      "        [-0.5895,  0.0112,  0.5614,  0.0474,  0.7043,  0.7286],\n",
      "        ...,\n",
      "        [-0.6559, -0.0441,  0.6054, -0.0018,  0.7613,  0.7600],\n",
      "        [-0.6573,  0.0572,  0.6204, -0.0395,  0.7168,  0.7416],\n",
      "        [-0.6227,  0.0130,  0.5947, -0.0192,  0.7588,  0.6910]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 4 [49152/129926 (38%)]\tLoss: 0.333683\tGrad Norm: 0.338433\tLR: 0.941192\n",
      "tensor([[-0.3606, -0.0238,  0.3756, -0.0955,  0.5732,  0.5772],\n",
      "        [-0.3573, -0.1387,  0.2825, -0.0372,  0.5646,  0.6409],\n",
      "        [-0.4021, -0.0436,  0.2846, -0.1375,  0.5509,  0.4783],\n",
      "        ...,\n",
      "        [-0.3304, -0.0425,  0.3884, -0.1082,  0.6090,  0.6306],\n",
      "        [-0.4445, -0.0885,  0.2620, -0.0081,  0.5535,  0.5328],\n",
      "        [-0.4214, -0.0857,  0.3146, -0.0932,  0.5894,  0.4943]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6378,  0.0128,  0.6587,  0.0741,  0.7116,  0.7819],\n",
      "        [-0.6343,  0.0126,  0.5941,  0.0315,  0.7358,  0.7738],\n",
      "        [-0.5784,  0.0386,  0.6464,  0.0824,  0.7915,  0.7298],\n",
      "        ...,\n",
      "        [-0.6433,  0.0369,  0.6497,  0.0064,  0.7629,  0.7523],\n",
      "        [-0.5649,  0.0030,  0.6518,  0.0501,  0.7727,  0.7691],\n",
      "        [-0.5467, -0.0048,  0.6537,  0.0740,  0.7271,  0.7446]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.3106, -0.0678,  0.4315, -0.1821,  0.4609,  0.5671],\n",
      "        [-0.3562,  0.0609,  0.4484, -0.0865,  0.5391,  0.5093],\n",
      "        [-0.4854, -0.0447,  0.3449, -0.0211,  0.4725,  0.5101],\n",
      "        ...,\n",
      "        [-0.3195, -0.0177,  0.3575, -0.0988,  0.5322,  0.5379],\n",
      "        [-0.3352, -0.1252,  0.3908, -0.0963,  0.5787,  0.6164],\n",
      "        [-0.3622, -0.0218,  0.4129,  0.0159,  0.5011,  0.5940]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6653,  0.0306,  0.6403,  0.0369,  0.7334,  0.7379],\n",
      "        [-0.6474,  0.0018,  0.6214,  0.0190,  0.7516,  0.7443],\n",
      "        [-0.6780, -0.0228,  0.6057,  0.0446,  0.7995,  0.7733],\n",
      "        ...,\n",
      "        [-0.6169,  0.0062,  0.5890,  0.0087,  0.7737,  0.7385],\n",
      "        [-0.6302,  0.0100,  0.6040,  0.0527,  0.7502,  0.7428],\n",
      "        [-0.6719,  0.0011,  0.6119,  0.0309,  0.7906,  0.7509]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.3534, -0.0778,  0.3395, -0.0533,  0.4822,  0.6286],\n",
      "        [-0.3267, -0.0319,  0.2980, -0.0776,  0.4674,  0.5854],\n",
      "        [-0.4254,  0.0261,  0.2946, -0.1134,  0.5926,  0.5635],\n",
      "        ...,\n",
      "        [-0.3760, -0.0542,  0.3611, -0.0166,  0.4997,  0.3485],\n",
      "        [-0.4003,  0.0102,  0.3147,  0.0234,  0.6082,  0.5850],\n",
      "        [-0.3857,  0.0552,  0.2712, -0.1540,  0.5571,  0.6185]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 4 [90112/129926 (69%)]\tLoss: 0.328430\tGrad Norm: 0.317860\tLR: 0.941192\n",
      "tensor([[-0.6501, -0.0415,  0.6187,  0.0224,  0.7254,  0.7380],\n",
      "        [-0.5895, -0.0157,  0.5806,  0.0496,  0.7278,  0.7246],\n",
      "        [-0.6550,  0.0012,  0.6263, -0.0475,  0.7512,  0.6846],\n",
      "        ...,\n",
      "        [-0.5787, -0.0111,  0.5977,  0.0360,  0.7032,  0.7762],\n",
      "        [-0.6223,  0.0051,  0.5742,  0.0211,  0.7376,  0.7275],\n",
      "        [-0.6475,  0.0272,  0.6395, -0.0024,  0.7357,  0.7672]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.3926, -0.0889,  0.2291, -0.0663,  0.6484,  0.5211],\n",
      "        [-0.2744, -0.0777,  0.3134,  0.0030,  0.5712,  0.5981],\n",
      "        [-0.3930, -0.1277,  0.4490, -0.1050,  0.4269,  0.4902],\n",
      "        ...,\n",
      "        [-0.2972, -0.0586,  0.4671, -0.0268,  0.5907,  0.5443],\n",
      "        [-0.3083,  0.0674,  0.3132, -0.0228,  0.5473,  0.5671],\n",
      "        [-0.3861, -0.0274,  0.4207, -0.0279,  0.6185,  0.6299]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.5820,  0.0826,  0.6039, -0.0300,  0.7226,  0.7203],\n",
      "        [-0.5455,  0.0420,  0.6239,  0.0018,  0.7511,  0.7333],\n",
      "        [-0.5764,  0.0911,  0.6017, -0.0157,  0.7327,  0.7623],\n",
      "        ...,\n",
      "        [-0.5759,  0.0920,  0.6167, -0.0153,  0.7245,  0.7371],\n",
      "        [-0.5767,  0.0222,  0.6039, -0.0103,  0.6988,  0.7467],\n",
      "        [-0.5821,  0.1016,  0.5920, -0.0413,  0.7817,  0.7311]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.3807, -0.1334,  0.3558,  0.0783,  0.5867,  0.5982],\n",
      "        [-0.3527, -0.0708,  0.3552,  0.0506,  0.5429,  0.6052],\n",
      "        [-0.4681, -0.1206,  0.3184, -0.1007,  0.6035,  0.6432],\n",
      "        ...,\n",
      "        [-0.4322, -0.1123,  0.3888, -0.0247,  0.5796,  0.5721],\n",
      "        [-0.4113, -0.0548,  0.3467, -0.0701,  0.5796,  0.6447],\n",
      "        [-0.3794, -0.0610,  0.3617, -0.0079,  0.5983,  0.4987]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "tensor([[-0.6076,  0.1164,  0.5454, -0.0085,  0.6960,  0.7294],\n",
      "        [-0.6160,  0.0782,  0.5867, -0.0051,  0.6770,  0.7491],\n",
      "        [-0.6473,  0.0816,  0.5483, -0.0785,  0.7100,  0.7419],\n",
      "        ...,\n",
      "        [-0.6295,  0.0681,  0.5630,  0.0124,  0.7406,  0.7152],\n",
      "        [-0.5800,  0.0953,  0.5543,  0.0030,  0.7552,  0.7127],\n",
      "        [-0.6152,  0.1084,  0.5857,  0.0329,  0.7459,  0.6873]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n",
      "Train Epoch: 4 [131072/129926 (100%)]\tLoss: 0.328562\tGrad Norm: 0.284787\tLR: 0.941192\n",
      "Train set: Average loss: 0.3312\n"
     ]
    }
   ],
   "source": [
    "pretrain_agent(\n",
    "    model,\n",
    "    expert_observations,\n",
    "    expert_actions,\n",
    "    env,\n",
    "    test_env = eval_env,\n",
    "    batch_size=4096*2,\n",
    "    epochs=500,\n",
    "    scheduler_gamma=0.98,\n",
    "    learning_rate=1.0,\n",
    "    log_interval=5,\n",
    "    no_cuda=False,\n",
    "    seed=1,\n",
    "    verbose=True,\n",
    "    test_batch_size=512,\n",
    "    early_stopping_patience=300,\n",
    "    plot_curves=True,\n",
    "    tensorboard_log_dir=\"tb_logs/imitation\",\n",
    "    save_path=\"checkpoints/imitation_SAC\",\n",
    "    comet_ml_api_key=\"No20MKxPKu7vWLOUQCFBRO8mo\",\n",
    "    comet_ml_project_name=\"pretraining_rl\",\n",
    "    comet_ml_experiment_name=\"PPO_1\",\n",
    "    eval_freq = 5,\n",
    "    l2_reg_strength=0.0000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820005a-be57-4236-b66b-0b34ed558aff",
   "metadata": {},
   "source": [
    "---\n",
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3e210c1-817a-42a8-ab28-2ea437ed2c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 64 cpus!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from transformers import AutoTokenizer, AutoModel\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecCheckNan\n",
    "import multiprocessing\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\")\n",
    "#model = AutoModel.from_pretrained(\"huggingface/CodeBERTa-small-v1\").to('cuda')\n",
    "\n",
    "# Set number of cpus to use automatically:\n",
    "num_cpu = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Using {} cpus!\".format(num_cpu))\n",
    "observation_type = \"image\"\n",
    "\n",
    "train_env = sogym(mode='train',observation_type=observation_type,vol_constraint_type = 'hard',resolution=50,check_connectivity=True)#,model=model,tokenizer=tokenizer)\n",
    "env= make_vec_env(lambda:train_env, n_envs=num_cpu,vec_env_cls=SubprocVecEnv)\n",
    "env = VecCheckNan(env, raise_exception=True)\n",
    "#env=VecNormalize(env,gamma=1.0)\n",
    "\n",
    "eval_env = sogym(mode='test',observation_type=observation_type,vol_constraint_type='hard',resolution=50,check_connectivity=True)#,model=model,tokenizer=tokenizer)\n",
    "eval_env = make_vec_env(lambda:eval_env, n_envs=1,vec_env_cls=SubprocVecEnv)\n",
    "#eval_env =VecNormalize(eval_env,gamma=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b6f2e-5ceb-447f-ac10-a52f0379cb31",
   "metadata": {},
   "source": [
    "--- \n",
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1132db-34f4-4a72-bb12-1339a9e00a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.5 * np.ones(n_actions))\n",
    "\n",
    "chosen_policy = \"MlpPolicy\" if observation_type == 'box_dense' else \"MultiInputPolicy\"\n",
    "\n",
    "feature_extractor = ImageDictExtractor if observation_type == 'image' else CustomBoxDense\n",
    "\n",
    "# Load the YAML file\n",
    "\n",
    "with open(\"algorithms.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Extract the parameters for the desired algorithm\n",
    "algorithm_name = \"SAC\"  # or \"TD3\"\n",
    "algorithm_params = config[algorithm_name]\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=feature_extractor,\n",
    "    net_arch = config['common']['net_arch'],\n",
    "    share_features_extractor = False,\n",
    ")\n",
    "\n",
    "# Create the model based on the algorithm name and parameters\n",
    "if algorithm_name == \"SAC\":\n",
    "    model = SAC(env=env,\n",
    "                policy = chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                #action_noise = action_noise,\n",
    "                device=device, \n",
    "                **algorithm_params)\n",
    "\n",
    "elif algorithm_name == \"PPO\":\n",
    "    model = PPO(env=env, \n",
    "                policy = chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                device = device, \n",
    "                **algorithm_params)\n",
    "\n",
    "elif algorithm_name == \"TD3\":\n",
    "    # Create the action noise object\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "    action_noise_params = algorithm_params.pop(\"action_noise\")\n",
    "    action_noise = NormalActionNoise(mean=action_noise_params[\"mean\"] * np.ones(n_actions),\n",
    "                                     sigma=action_noise_params[\"sigma\"] * np.ones(n_actions))\n",
    "    model = TD3(env=env,\n",
    "                policy =chosen_policy, \n",
    "                policy_kwargs=policy_kwargs,\n",
    "                action_noise=action_noise,\n",
    "                device=device, \n",
    "                **algorithm_params)\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create the tb_log_name string\n",
    "tb_log_name = f\"{algorithm_name}_{current_datetime}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec8bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a checkpoint every 1000 steps\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=50000//num_cpu,\n",
    "  save_path=\"./checkpoints/\",\n",
    "  name_prefix=tb_log_name,\n",
    "  save_replay_buffer=True,\n",
    "  save_vecnormalize=True,\n",
    ")\n",
    "\n",
    "eval_callback = EvalCallback(eval_env,\n",
    "                             log_path='tb_logs',\n",
    "                             eval_freq=5000//num_cpu,\n",
    "                             deterministic=True,\n",
    "                            n_eval_episodes=10,\n",
    "                             render=False,\n",
    "                             best_model_save_path='./checkpoints',\n",
    "                             verbose=0)\n",
    "import torch\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class GradientClippingCallback(BaseCallback):\n",
    "    def __init__(self, clip_value: float, verbose: int = 0):\n",
    "        super().__init__(verbose)\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if hasattr(self.model, \"policy\"):\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.policy.parameters(), self.clip_value)\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "callback_list = CallbackList([eval_callback,\n",
    "                         checkpoint_callback,\n",
    "                         MaxRewardCallback(verbose=1),\n",
    "                         GradientClippingCallback(clip_value=10.0, verbose=1),\n",
    "                         GradientNormCallback(verbose=1),\n",
    "                         FigureRecorderCallback(check_freq=5000//num_cpu,eval_env=eval_env)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f70cf1-e15e-4fed-ab75-12bdca996f2d",
   "metadata": {},
   "source": [
    "--- \n",
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a84e3f",
   "metadata": {},
   "source": [
    "Save the model:\n",
    "\n",
    "If model is on-policy:\n",
    "#model.save(\"sac_pendulum\")\n",
    "#loaded_model = SAC.load(\"sac_pendulum\")\n",
    "\n",
    "if model is off-policy, we also need to save the replay buffer:\n",
    "#model.save_replay_buffer(\"sac_replay_buffer\")\n",
    "#loaded_model.load_replay_buffer(\"sac_replay_buffer\")\n",
    "\n",
    "If the environment is normalized:\n",
    "#env.save('env_saved.pkl')\n",
    "#env = VecNormalize.load('env_saved.pkl',env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d340e775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor.features_extractor.extractors.design_variables.0.weight torch.Size([128, 48])\n",
      "actor.features_extractor.extractors.design_variables.0.bias torch.Size([128])\n",
      "actor.features_extractor.extractors.design_variables.3.weight torch.Size([128, 128])\n",
      "actor.features_extractor.extractors.design_variables.3.bias torch.Size([128])\n",
      "actor.features_extractor.extractors.image.0.weight torch.Size([32, 3, 3, 3])\n",
      "actor.features_extractor.extractors.image.0.bias torch.Size([32])\n",
      "actor.features_extractor.extractors.image.3.weight torch.Size([64, 32, 3, 3])\n",
      "actor.features_extractor.extractors.image.3.bias torch.Size([64])\n",
      "actor.features_extractor.extractors.image.6.weight torch.Size([128, 64, 3, 3])\n",
      "actor.features_extractor.extractors.image.6.bias torch.Size([128])\n",
      "actor.features_extractor.extractors.n_steps_left.0.weight torch.Size([128, 1])\n",
      "actor.features_extractor.extractors.n_steps_left.0.bias torch.Size([128])\n",
      "actor.features_extractor.extractors.n_steps_left.3.weight torch.Size([128, 128])\n",
      "actor.features_extractor.extractors.n_steps_left.3.bias torch.Size([128])\n",
      "actor.features_extractor.extractors.score.0.weight torch.Size([128, 1])\n",
      "actor.features_extractor.extractors.score.0.bias torch.Size([128])\n",
      "actor.features_extractor.extractors.score.3.weight torch.Size([128, 128])\n",
      "actor.features_extractor.extractors.score.3.bias torch.Size([128])\n",
      "actor.features_extractor.extractors.structure_strain_energy.0.weight torch.Size([32, 3, 3, 3])\n",
      "actor.features_extractor.extractors.structure_strain_energy.0.bias torch.Size([32])\n",
      "actor.features_extractor.extractors.structure_strain_energy.3.weight torch.Size([64, 32, 3, 3])\n",
      "actor.features_extractor.extractors.structure_strain_energy.3.bias torch.Size([64])\n",
      "actor.features_extractor.extractors.structure_strain_energy.6.weight torch.Size([128, 64, 3, 3])\n",
      "actor.features_extractor.extractors.structure_strain_energy.6.bias torch.Size([128])\n",
      "actor.features_extractor.extractors.volume.0.weight torch.Size([128, 1])\n",
      "actor.features_extractor.extractors.volume.0.bias torch.Size([128])\n",
      "actor.features_extractor.extractors.volume.3.weight torch.Size([128, 128])\n",
      "actor.features_extractor.extractors.volume.3.bias torch.Size([128])\n",
      "actor.latent_pi.0.weight torch.Size([512, 16896])\n",
      "actor.latent_pi.0.bias torch.Size([512])\n",
      "actor.latent_pi.2.weight torch.Size([512, 512])\n",
      "actor.latent_pi.2.bias torch.Size([512])\n",
      "actor.latent_pi.4.weight torch.Size([512, 512])\n",
      "actor.latent_pi.4.bias torch.Size([512])\n",
      "actor.mu.weight torch.Size([6, 512])\n",
      "actor.mu.bias torch.Size([6])\n",
      "actor.log_std.weight torch.Size([6, 512])\n",
      "actor.log_std.bias torch.Size([6])\n",
      "critic.features_extractor.extractors.design_variables.0.weight torch.Size([128, 48])\n",
      "critic.features_extractor.extractors.design_variables.0.bias torch.Size([128])\n",
      "critic.features_extractor.extractors.design_variables.3.weight torch.Size([128, 128])\n",
      "critic.features_extractor.extractors.design_variables.3.bias torch.Size([128])\n",
      "critic.features_extractor.extractors.image.0.weight torch.Size([32, 3, 3, 3])\n",
      "critic.features_extractor.extractors.image.0.bias torch.Size([32])\n",
      "critic.features_extractor.extractors.image.3.weight torch.Size([64, 32, 3, 3])\n",
      "critic.features_extractor.extractors.image.3.bias torch.Size([64])\n",
      "critic.features_extractor.extractors.image.6.weight torch.Size([128, 64, 3, 3])\n",
      "critic.features_extractor.extractors.image.6.bias torch.Size([128])\n",
      "critic.features_extractor.extractors.n_steps_left.0.weight torch.Size([128, 1])\n",
      "critic.features_extractor.extractors.n_steps_left.0.bias torch.Size([128])\n",
      "critic.features_extractor.extractors.n_steps_left.3.weight torch.Size([128, 128])\n",
      "critic.features_extractor.extractors.n_steps_left.3.bias torch.Size([128])\n",
      "critic.features_extractor.extractors.score.0.weight torch.Size([128, 1])\n",
      "critic.features_extractor.extractors.score.0.bias torch.Size([128])\n",
      "critic.features_extractor.extractors.score.3.weight torch.Size([128, 128])\n",
      "critic.features_extractor.extractors.score.3.bias torch.Size([128])\n",
      "critic.features_extractor.extractors.structure_strain_energy.0.weight torch.Size([32, 3, 3, 3])\n",
      "critic.features_extractor.extractors.structure_strain_energy.0.bias torch.Size([32])\n",
      "critic.features_extractor.extractors.structure_strain_energy.3.weight torch.Size([64, 32, 3, 3])\n",
      "critic.features_extractor.extractors.structure_strain_energy.3.bias torch.Size([64])\n",
      "critic.features_extractor.extractors.structure_strain_energy.6.weight torch.Size([128, 64, 3, 3])\n",
      "critic.features_extractor.extractors.structure_strain_energy.6.bias torch.Size([128])\n",
      "critic.features_extractor.extractors.volume.0.weight torch.Size([128, 1])\n",
      "critic.features_extractor.extractors.volume.0.bias torch.Size([128])\n",
      "critic.features_extractor.extractors.volume.3.weight torch.Size([128, 128])\n",
      "critic.features_extractor.extractors.volume.3.bias torch.Size([128])\n",
      "critic.qf0.0.weight torch.Size([512, 16902])\n",
      "critic.qf0.0.bias torch.Size([512])\n",
      "critic.qf0.2.weight torch.Size([512, 512])\n",
      "critic.qf0.2.bias torch.Size([512])\n",
      "critic.qf0.4.weight torch.Size([512, 512])\n",
      "critic.qf0.4.bias torch.Size([512])\n",
      "critic.qf0.6.weight torch.Size([1, 512])\n",
      "critic.qf0.6.bias torch.Size([1])\n",
      "critic.qf1.0.weight torch.Size([512, 16902])\n",
      "critic.qf1.0.bias torch.Size([512])\n",
      "critic.qf1.2.weight torch.Size([512, 512])\n",
      "critic.qf1.2.bias torch.Size([512])\n",
      "critic.qf1.4.weight torch.Size([512, 512])\n",
      "critic.qf1.4.bias torch.Size([512])\n",
      "critic.qf1.6.weight torch.Size([1, 512])\n",
      "critic.qf1.6.bias torch.Size([1])\n",
      "critic_target.features_extractor.extractors.design_variables.0.weight torch.Size([128, 48])\n",
      "critic_target.features_extractor.extractors.design_variables.0.bias torch.Size([128])\n",
      "critic_target.features_extractor.extractors.design_variables.3.weight torch.Size([128, 128])\n",
      "critic_target.features_extractor.extractors.design_variables.3.bias torch.Size([128])\n",
      "critic_target.features_extractor.extractors.image.0.weight torch.Size([32, 3, 3, 3])\n",
      "critic_target.features_extractor.extractors.image.0.bias torch.Size([32])\n",
      "critic_target.features_extractor.extractors.image.3.weight torch.Size([64, 32, 3, 3])\n",
      "critic_target.features_extractor.extractors.image.3.bias torch.Size([64])\n",
      "critic_target.features_extractor.extractors.image.6.weight torch.Size([128, 64, 3, 3])\n",
      "critic_target.features_extractor.extractors.image.6.bias torch.Size([128])\n",
      "critic_target.features_extractor.extractors.n_steps_left.0.weight torch.Size([128, 1])\n",
      "critic_target.features_extractor.extractors.n_steps_left.0.bias torch.Size([128])\n",
      "critic_target.features_extractor.extractors.n_steps_left.3.weight torch.Size([128, 128])\n",
      "critic_target.features_extractor.extractors.n_steps_left.3.bias torch.Size([128])\n",
      "critic_target.features_extractor.extractors.score.0.weight torch.Size([128, 1])\n",
      "critic_target.features_extractor.extractors.score.0.bias torch.Size([128])\n",
      "critic_target.features_extractor.extractors.score.3.weight torch.Size([128, 128])\n",
      "critic_target.features_extractor.extractors.score.3.bias torch.Size([128])\n",
      "critic_target.features_extractor.extractors.structure_strain_energy.0.weight torch.Size([32, 3, 3, 3])\n",
      "critic_target.features_extractor.extractors.structure_strain_energy.0.bias torch.Size([32])\n",
      "critic_target.features_extractor.extractors.structure_strain_energy.3.weight torch.Size([64, 32, 3, 3])\n",
      "critic_target.features_extractor.extractors.structure_strain_energy.3.bias torch.Size([64])\n",
      "critic_target.features_extractor.extractors.structure_strain_energy.6.weight torch.Size([128, 64, 3, 3])\n",
      "critic_target.features_extractor.extractors.structure_strain_energy.6.bias torch.Size([128])\n",
      "critic_target.features_extractor.extractors.volume.0.weight torch.Size([128, 1])\n",
      "critic_target.features_extractor.extractors.volume.0.bias torch.Size([128])\n",
      "critic_target.features_extractor.extractors.volume.3.weight torch.Size([128, 128])\n",
      "critic_target.features_extractor.extractors.volume.3.bias torch.Size([128])\n",
      "critic_target.qf0.0.weight torch.Size([512, 16902])\n",
      "critic_target.qf0.0.bias torch.Size([512])\n",
      "critic_target.qf0.2.weight torch.Size([512, 512])\n",
      "critic_target.qf0.2.bias torch.Size([512])\n",
      "critic_target.qf0.4.weight torch.Size([512, 512])\n",
      "critic_target.qf0.4.bias torch.Size([512])\n",
      "critic_target.qf0.6.weight torch.Size([1, 512])\n",
      "critic_target.qf0.6.bias torch.Size([1])\n",
      "critic_target.qf1.0.weight torch.Size([512, 16902])\n",
      "critic_target.qf1.0.bias torch.Size([512])\n",
      "critic_target.qf1.2.weight torch.Size([512, 512])\n",
      "critic_target.qf1.2.bias torch.Size([512])\n",
      "critic_target.qf1.4.weight torch.Size([512, 512])\n",
      "critic_target.qf1.4.bias torch.Size([512])\n",
      "critic_target.qf1.6.weight torch.Size([1, 512])\n",
      "critic_target.qf1.6.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Print all the model.policy parameters:\n",
    "\n",
    "for name, param in model.policy.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "978d7768-b7bb-4c14-b620-28a278392b6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:414: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_check_nan.VecCheckNan object at 0x7fc93411bc70> != <stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fbb05e93010>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_wrapper_attr('reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/thomas/anaconda3/envs/SB3_update/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.plot to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.plot` for environment variables or `env.get_wrapper_attr('plot')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mset_parameters(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/imitation_SAC.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#model.set_parameters(\"imitation_SAC_critic\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# #Freeze everything:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#print(model.batch_size)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#model.load_replay_buffer(\"sac_replay_buffer\")\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20000000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#model.save('model_saved_march15',)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#model.save_replay_buffer(\"sac_replay_buffer_march15\")\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#env.save('env_saved.pkl')\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/sac/sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[1;32m    300\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSAC:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:328\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 328\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:560\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    557\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    563\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_check_nan.py:40\u001b[0m, in \u001b[0;36mVecCheckNan.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m---> 40\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_val(event\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_wait\u001b[39m\u001b[38;5;124m\"\u001b[39m, observations\u001b[38;5;241m=\u001b[39mobservations, rewards\u001b[38;5;241m=\u001b[39mrewards, dones\u001b[38;5;241m=\u001b[39mdones)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observations \u001b[38;5;241m=\u001b[39m observations\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py:129\u001b[0m, in \u001b[0;36mSubprocVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m--> 129\u001b[0m     results \u001b[38;5;241m=\u001b[39m [remote\u001b[38;5;241m.\u001b[39mrecv() \u001b[38;5;28;01mfor\u001b[39;00m remote \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremotes]\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwaiting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     obs, rews, dones, infos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py:129\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m--> 129\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\u001b[43mremote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m remote \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremotes]\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwaiting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     obs, rews, dones, infos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SB3_update/lib/python3.10/multiprocessing/connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m    255\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recv_bytes()\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model = SAC.load(\"checkpoints/imitation_SAC\",env =env) #Saved model is with soft volume constraint and 75 r\n",
    "model.set_parameters(\"checkpoints/imitation_SAC.zip\")\n",
    "#model.set_parameters(\"imitation_SAC_critic\")\n",
    "\n",
    "# #Freeze everything:\n",
    "# for name, param in model.policy.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         param.requires_grad=False\n",
    "\n",
    "# # Unfreeze critic:\n",
    "# for param in model.policy.critic.parameters():\n",
    "#     if param.requires_grad==False:\n",
    "#         param.requires_grad=True\n",
    "\n",
    "# for param in model.policy.critic_target.parameters():\n",
    "#     if param.requires_grad==False:\n",
    "#         param.requires_grad=True\n",
    " \n",
    "# #Reset critic networks:\n",
    "# if hasattr(model.policy.critic_target, 'reset_parameters'):\n",
    "#     print(' resetting')\n",
    "#     model.policy.critic_target.reset_parameters()\n",
    "    \n",
    "# if hasattr(model.policy.critic, 'reset_parameters'):\n",
    "#     print(' resetting')\n",
    "#     model.policy.critic_target.reset_parameters() \n",
    "\n",
    "#print(model.batch_size)\n",
    "#model.load_replay_buffer(\"sac_replay_buffer\")\n",
    "model.learn(20000000,\n",
    "            callback=callback_list, \n",
    "            tb_log_name=tb_log_name\n",
    "            )\n",
    "#model.save('model_saved_march15',)\n",
    "#model.save_replay_buffer(\"sac_replay_buffer_march15\")\n",
    "\n",
    "#env.save('env_saved.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27da122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('imitation_SAC_critic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827c8cc-028d-4448-b109-d6542816df2a",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's visualize the agent's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728408e-71c2-4f7b-a8f1-f0cc6b43dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=sogym(mode='train',observation_type='image',vol_constraint_type='hard' ,resolution = 50)\n",
    "#env= make_vec_env(lambda:env, n_envs=1,vec_env_cls=SubprocVecEnv)\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cbb153d-80e3-4d6c-ada3-f4d323360b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.45084208 -0.6196898   0.09775901  0.08562005 -0.6068028  -0.2731769 ]\n",
      "[-0.39078236 -0.552323    0.06692231  0.00492871 -0.60554457 -0.31692517]\n",
      "[-0.38510835 -0.15872407  0.07184839 -0.38176912 -0.5579868  -0.32513887]\n",
      "[-0.34414232 -0.05186987  0.03793955 -0.3199352  -0.514287   -0.32949364]\n",
      "[-0.3365829   0.2699256   0.04909801 -0.40723407 -0.39889908 -0.256208  ]\n",
      "[-0.21261054  0.1356157   0.11291325 -0.26657045 -0.36370713 -0.2738819 ]\n",
      "[-0.05037349  0.02053773  0.3253739  -0.32322854 -0.29293525 -0.2721809 ]\n",
      "[-0.00223839  0.0816108   0.41234756 -0.17857927 -0.24306583 -0.32128817]\n",
      "Desired volume: 0.31 Obtained volume: 0.061391948215072954\n",
      "Env reward: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs,info=env.reset()\n",
    "dones=False\n",
    "saved_conditions = env.conditions\n",
    "saved_nelx, saved_nely = env.nelx, env.nely\n",
    "saved_dx, saved_dy = env.dx, env.dy\n",
    "#use deepcopy to save \n",
    "while dones== False:\n",
    "    action, _states = model.predict(obs,deterministic=True)\n",
    "    print(action)\n",
    "    obs, rewards, dones,truncated, info = env.step(action)\n",
    "print(\"Desired volume:\",saved_conditions['volfrac'],\"Obtained volume:\",env.volume)\n",
    "print(\"Env reward:\",rewards)\n",
    "env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2de1f-dd90-40b2-acc9-b3227fd2888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xval, f0val,it, H, Phimax, allPhi, den, N, cfg = run_mmc(saved_conditions,saved_nelx,saved_nely,saved_dx,saved_dy,plotting='contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5491c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('SB3_update')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e21ef5adabae340b8408649b4e28a9d7d4d8eaab8fdd4faf01af585df564eed2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
